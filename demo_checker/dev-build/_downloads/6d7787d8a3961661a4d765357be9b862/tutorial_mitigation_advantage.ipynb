{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Is quantum computing useful before fault tolerance?\n===================================================\n\n::: {.meta}\n:property=\\\"og:description\\\": Evidence for the utility of quantum\ncomputing before fault tolerance :property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/thumbnail_tutorial_mitigation_advantage.png>\n:::\n\n::: {.related}\ntutorial\\_error\\_mitigation Error mitigation with Mitiq and PennyLane\ntutorial\\_diffable-mitigation Differentiable quantum error mitigation\ntutorial\\_noisy\\_circuits Noisy circuits gbs Quantum advantage with\nGaussian Boson Sampling\n:::\n\n*Author: Korbinian Kottmann --- Posted: 16 June 2023.*\n\nCan we use contemporary quantum computers for tasks that are both useful\n*and* hard to classically simulate? A recent [Nature\npaper](https://www.nature.com/articles/s41586-023-06096-3) from the team\nat IBM claims that we can! See how they managed to faithfully estimate\nexpectation values of reasonably large and reasonably deep quantum\ncircuits using an exciting new\n`zero noise extrapolation <tutorial_diffable-mitigation>`{.interpreted-text\nrole=\"doc\"} technique for error mitigation in this demo.\n\nIntroduction\n------------\n\nWe know that quantum computers can do things that classical computers\ncannot. But quantum algorithms like Shor\\'s algorithm necessitate fault\ntolerance via error correction, which is not yet feasible with currently\navailable machines. One highly debated question in the field is whether\nor not noisy devices we have access to [right now]{.title-ref} are\nalready useful or can outperform a classical computer for certain tasks.\nFor the latter point, demonstrations of quantum computational advantage\nhave been put forward with the [2019\nSycamore](https://www.nature.com/articles/s41586-019-1666-5) (Google),\nthe [2020 Jiuzhang](https://www.science.org/doi/10.1126/science.abe8770)\n(Chinese academy of science) and the [2022\nBorealis](https://www.nature.com/articles/s41586-022-04725-x) (Xanadu)\nexperiments. These demonstrations, however, are only of limited\npractical utility.\n\nA new quest has been set out for \\'practical\\' quantum computational\nadvantage. That is, a \\'useful\\' application for which a quantum\ncomputer outperforms the best known classical methods. In the new\narticle by a team of scientists at IBM, a case is made that with their\nlatest device\n[ibm\\_kyiv](https://quantum-computing.ibm.com/services/resources?system=ibm_kyiv)\ncomprising 127 qubits and record-breaking coherence times, they can\nfaithfully simulate the time dynamics of a complex quantum many-body\nsystem. One of the key achievements of the paper is the successful\napplication of error mitigation on a large system (that is making use of\na learned noise model), and demonstrating that it can yield faithful\nresults even in very noisy scenarios with reasonably deep circuits.\n\nProblem setting\n---------------\n\nBefore we go into the details of the error mitigation methods, let us\nbriefly summarize the problem setting. The authors of are concerned with\nsimulating the time dynamics of the 2D transverse field Ising model\n\n$$H = -J \\sum_{\\langle qp \\rangle}Z_q Z_p + h \\sum_q X_q,$$\n\nwith nearest neighbor interactions (indicated by $\\langle qp \\rangle$)\nmatching the topology of their 127-qubit\n[ibm\\_kyiv](https://quantum-computing.ibm.com/services/resources?system=ibm_kyiv)\ndevice. The system is described by the positive coupling strength $J$\nand transverse field [h]{.title-ref}. The time evolution is approximated\nby trotterization of the time evolution operator\n\n$$U(T) \\approx \\left(\\prod_{\\langle qp \\rangle} e^{i \\delta t J Z_q Z_p} \\prod_{q} e^{-i \\delta t J X_q} \\right)^{\\frac{T}{\\delta t}}$$\n\nfor an evolution time $T$ and a Trotter step size $\\delta t$. That means\nthe circuit of concern here is a series of consecutive\n$\\text{RZZ}(\\theta_J)$ and $\\text{RX}(\\theta_h)$ rotations. The\ncorresponding angles are related to the physical parameters via\n$\\theta_J = -2J \\delta t$ and $\\theta_h = 2h \\delta t$\\`\\`[. From here\non, we are going to focus just on the values of\n:math:]{.title-ref}theta\\_h\\` and keep $\\theta_J=-\\pi/2$ fixed (in the\npaper, this is due to the simplification this introduces in the\ndecomposition of the $\\text{RZZ}$ gate in terms of the required CNOT\ngates).\n\n### Noisy simulation of the circuits\n\nThe complexity of the classical simulation varies with the parameter\n$\\theta_h$. For the extrema $\\theta_h=0$ and $\\theta_h=\\pi/2$, the\nsystem becomes trivially solvable. We interpolate between those extrema\nand show the final value of a single weight observable\n$\\langle Z_4\\rangle$ as is done in.\n\nTo reproduce the key ingredients of, we are going to simulate a scaled\ndown version of the real system using PennyLane. Instead of 127 qubits,\nwe will use only 9, placed on a $3 \\times 3$ grid with nearest neighbor\ninteractions. We start by setting up the circuits for the time evolution\nand a noise model consisting of\n`~pennylane.DepolarizingChannel`{.interpreted-text role=\"class\"} applied\nto each gate the circuit executes. Physically, this corresponds to\napplying either of the single qubit Pauli gates $\\{X, Y, Z\\}$ with\nprobability $p/3$ after each gate in the circuit. In simulation, we can\nsimply look at the classical mixtures introduced by the Kraus operators\nof the noise channel. That is why we need to use the mixed state\nsimulator. For more information see e.g. our\n`demo on simulating noisy circuits <tutorial_noisy_circuits>`{.interpreted-text\nrole=\"doc\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nimport jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\njax.config.update(\"jax_enable_x64\", True)\njax.config.update('jax_platform_name', 'cpu')\n\nn_wires = 9\n# Describe noise\nnoise_gate = qml.DepolarizingChannel\np = 0.005\n\n# Load devices\ndev_ideal = qml.device(\"default.mixed\", wires=n_wires)\ndev_noisy = qml.transforms.insert(noise_gate, p, position=\"all\")(dev_ideal)\n\n# 3x3 grid with nearest neighbors\nconnections = [(0, 1), (1, 2),\n               (3, 4), (4, 5),\n               (6, 7), (7, 8),\n               (0, 3), (3, 6),\n               (1, 4), (4, 7),\n               (2, 5), (5, 8)]\n\ndef time_evolution(theta_h, n_layers = 10, obs = qml.PauliZ(4)):\n    for _ in range(n_layers):\n        for i, j in connections:\n            qml.IsingZZ(-jnp.pi/2, wires=(i, j))\n        for i in range(n_wires):\n            qml.RX(theta_h, wires=i)\n    return qml.expval(obs)\n\nqnode_ideal = qml.QNode(time_evolution, dev_ideal, interface=\"jax\")\nqnode_noisy = qml.QNode(time_evolution, dev_noisy, interface=\"jax\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now simulate the final expectation value with and without noise.\nWe use `jax.vmap` to vectorize and speed up the execution for different\nvalues of $\\theta_h$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thetas = jnp.linspace(0, jnp.pi/2, 50)\n\nres_ideal = jax.vmap(qnode_ideal)(thetas)\nres_noisy = jax.vmap(qnode_noisy)(thetas)\n\nplt.plot(thetas, res_ideal, label=\"exact\")\nplt.plot(thetas, res_noisy, label=\"noisy\")\nplt.xticks([0, jnp.pi/8, jnp.pi/4, 3*jnp.pi/8, jnp.pi/2], [\"0\", \"$\\\\pi$/8\", \"$\\\\pi/4$\", \"$3\\\\pi/4$\", \"$\\\\pi/2$\"])\nplt.xlabel(\"$\\\\theta_h$\")\nplt.ylabel(\"$\\\\langle Z_4 \\\\rangle$\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the fidelity of the result is decreased by the noise. Next,\nwe show how this noise can be effectively mitigated.\n\nError mitigation via zero noise extrapolation\n=============================================\n\n`Error mitigation <tutorial_error_mitigation>`{.interpreted-text\nrole=\"doc\"} is the process of retrieving more accurate information via\nclassical post-processing of noisy quantum executions. The authors in\nemploy zero noise extrapolation (ZNE), which serves as a biased\nestimator of expectation values. The idea of ZNE is fairly\nstraightforward: Imagine we want to obtain the exact quantum function\n$f$ that estimates an expectation value under noiseless evolution.\nHowever, we only have access to a noisy version $f^{\u26a1}$. Now suppose we\ncan controllably increase the noise present in terms of some noise gain\nparameter $G$. Here, $G=1$ corresponds to the default noise present in\nthe device. In ZNE, we evaluate $f^{\u26a1}$ at increasing values of $G,$\nfrom which we can extrapolate back to zero noise $G=0$ via a suitable\ncurve fit.\n\nIn order to perform ZNE, we need a control knob that increases the noise\nof our circuit execution. One such method is described in our\n`demo on differentiable error mitigation <tutorial_diffable-mitigation>`{.interpreted-text\nrole=\"doc\"} using circuit folding.\n\nNoise-aware ZNE\n---------------\n\nIn, the authors use a more sophisticated control knob to artificially\nincrease the noise. They first learn the parameters of an assumed noise\nmodel (in their case a Pauli Lindblad model) of their device. Ideally,\none would counteract those effects by probabilistically inverting the\nnoise action (probabilistic error cancellation). However, this comes\nwith an increased sampling overhead, which is not feasible for the size\nof their problem. So instead, they use the knowledge of the learned\nnoise model to artificially add extra noise and perform ZNE.\n\nThe noise model of our simulation is relatively simple and we have full\ncontrol over it. This means that we can simply attenuate the noise of\nour model by an appropriate gain factor. Here, $G=(1, 1.2, 1.6)$ in\naccordance with. In order to do this in PennyLane, we simply set up two\nnew noisy devices with the appropriately attenuated noise parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev_noisy1 = qml.transforms.insert(noise_gate, p*1.2, position=\"all\")(dev_ideal)\ndev_noisy2 = qml.transforms.insert(noise_gate, p*1.6, position=\"all\")(dev_ideal)\n\nqnode_noisy1 = qml.QNode(time_evolution, dev_noisy1, interface=\"jax\")\nqnode_noisy2 = qml.QNode(time_evolution, dev_noisy2, interface=\"jax\")\n\nres_noisy1 = jax.vmap(qnode_noisy1)(thetas)\nres_noisy2 = jax.vmap(qnode_noisy2)(thetas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can take these results and simply extrapolate back to $G=0$ with a\npolynomial fit. We can visualize this by plotting the noisy, exact and\nextrapolated results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Gs = jnp.array([1., 1.2, 1.6])\ny = jnp.array([res_noisy[0], res_noisy1[0], res_noisy2[0]])\ncoeff = jnp.polyfit(Gs, y, 2)\nx = jnp.linspace(0, 1.6, 100)\n\nplt.plot(x, jnp.polyval(coeff, x), label=\"fit\")\nplt.plot(Gs, y, \"x\", label=\"noisy results\")\nplt.plot([0], res_ideal[0], \"X\", label=\"exact result\")\nplt.xlabel(\"noise gain G\")\nplt.ylabel(\"$\\\\langle Z_4 \\\\rangle$\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now repeat this procedure for all values of $\\theta_h$ and see how\nthe results are much improved. We can use\n`~pennylane.transforms.richardson_extrapolate`{.interpreted-text\nrole=\"func\"} that performs a polynomial fit of a degree matching the\ninput data size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res_mitigated = [qml.transforms.richardson_extrapolate(Gs, [res_noisy[i], res_noisy1[i], res_noisy2[i]]) for i in range(len(res_ideal))]\n\nplt.plot(thetas, res_ideal, label=\"exact\")\nplt.plot(thetas, res_mitigated, label=\"mitigated\")\nplt.plot(thetas, res_noisy, label=\"noisy\")\nplt.xticks([0, jnp.pi/8, jnp.pi/4, 3*jnp.pi/8, jnp.pi/2], [\"0\", \"$\\\\pi$/8\", \"$\\\\pi/4$\", \"$3\\\\pi/4$\", \"$\\\\pi/2$\"])\nplt.xlabel(\"$\\\\theta_h$\")\nplt.ylabel(\"$\\\\langle Z_4 \\\\rangle$\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The big achievement in[^1] is that they managed to showcase the\nfeasibility of this approach on a large scale experimentally for their\ndevice. This is really good news, as it has not been clear whether or\nnot noise mitigation can be successfully employed on larger scales. The\nkey ingredient is the noise-aware attenuation, which allows for more\nrealistic and finer extrapolation at low resource overhead.\n\nComparison with classical methods\n=================================\n\nThe authors of[^2] compare their experimental results with classical\nmethods. For this, they consider three scenarios of different classical\ncomplexity.\n\nFor $\\theta_h=-\\pi/2$ (case 1) the dynamics become trivial with just a\nglobal phase factor introduced, such that starting from the initial\nstate $|0\\rangle^{\\otimes 127}$, the expectation values\n$\\langle Z_q \\rangle$ are trivially one at all times. This serves as an\nanchor point of orientation. Varying $\\theta_h$ (case 2) then increases\nthe classical simulation complexity. For the circuits chosen, it is\nstill possible to simulate the dynamical expectation values of local\nobservables by taking into account their light-cone in the evolution\nwith reduced depth (note that these are not full state vector evolutions\nbut rather just directly looking at the dynamical expectation values of\ninterest). In the third and most complex case, the circuit is altered\nsuch that the light-cone trick from before does not work anymore.\n\nOne of the points of the paper is to compare the experiments with\nsophisticated classical simulation methods. The authors chose tensor\nnetworks, in particular matrix product states (MPS) and isometric tensor\nnetwork states (isoTNS) for simulation. MPS are native to one\ndimensional topologies, but are often still employed for two dimensional\nsystems as is the case here. The justification for that is their lower\ncomputational and algorithmic complexity as well as the opportunity to\ndraw from decades of algorithmic development and optimization. Better\nsuited to the given problem are isoTNS, which are restrictions of\nprojected entangled pair states (PEPS) with some simplifications\nreducing the high computational and algorithmic complexity, at the cost\nof more approximation errors.\n\nIn both cases, the so-called bond-dimension $\\chi$, a hyperparameter\nchosen by the user, directly determines the bipartite entanglement\nentropy these states can capture. It is known that due to the area law\nof entanglement, many ground states of relevant physical system can be\nfaithfully approximated with suitably chosen tensor network states with\nfinite bond dimension. However, that is generally not the case for time\ndynamics as the entanglement entropy grows linearly and the area law no\nlonger holds. Therefore, the employed tensor network methods are doomed\nfor most dynamical simulations, as is showcased in the paper.\n\n[It can be\nargued](https://twitter.com/gppcarleo/status/1669251392156860418) that\nthere are better suited classical algorithms for these kind of dynamical\nsimulations, [with neural quantum states being one of\nthem](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.125.100503).\nFurther, tensor network methods in two and higher dimensions are\nextremely difficult to implement. The employed methods are not well\nsuited for the problem and do not grasp the full breadth of\npossibilities of classical simulation methods. We are curious to see\nwhat experts in the field will come up with to showcase faithful\nclassical simulations of these circuits.\n\nReferences\n==========\n\nAbout the author\n================\n\n[^1]: Youngseok Kim, Andrew Eddins, Sajant Anand, Ken Xuan Wei, Ewout\n    van den Berg, Sami Rosenblatt, Hasan Nayfeh, Yantao Wu, Michael\n    Zaletel, Kristan Temme & Abhinav Kandala \\\"Evidence for the utility\n    of quantum computing before fault tolerance\\\" [Nature 618,\n    500--505](https://www.nature.com/articles/s41586-023-06096-3), 2023.\n\n[^2]: Youngseok Kim, Andrew Eddins, Sajant Anand, Ken Xuan Wei, Ewout\n    van den Berg, Sami Rosenblatt, Hasan Nayfeh, Yantao Wu, Michael\n    Zaletel, Kristan Temme & Abhinav Kandala \\\"Evidence for the utility\n    of quantum computing before fault tolerance\\\" [Nature 618,\n    500--505](https://www.nature.com/articles/s41586-023-06096-3), 2023.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}