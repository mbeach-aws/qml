{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch and noisy devices {#pytorch_noise}\n=========================\n\n::: {.meta}\n:property=\\\"og:description\\\": Extend PyTorch with real quantum computing\npower, by using it to optimize a noisy quantum hardware device.\n:property=\\\"og:image\\\": <https://pennylane.ai/qml/_images/bloch.gif>\n:::\n\n::: {.related}\ntutorial\\_noisy\\_circuit\\_optimization Optimizing noisy circuits with\nCirq\n:::\n\n*Author: Josh Izaac --- Posted: 11 October 2019. Last updated: 9\nNovember 2022.*\n\nLet\\'s revisit the original\n`qubit rotation <qubit_rotation>`{.interpreted-text role=\"ref\"}\ntutorial, but instead of using the default NumPy/autograd QNode\ninterface, we\\'ll use the\n`introduction/interfaces/torch`{.interpreted-text role=\"doc\"}. We\\'ll\nalso replace the `default.qubit` device with a noisy `rigetti.qvm`\ndevice, to see how the optimization responds to noisy qubits. At the end\nof the demonstration, we will also show a way of how Rigetti\\'s QPU can\nbe used via Amazon Braket.\n\nTo follow along with this tutorial on your own computer, you will\nrequire the following dependencies:\n\n-   The [Rigetti SDK](https://qcs.rigetti.com/sdk-downloads), which\n    contains the quantum virtual machine (QVM) and quilc quantum\n    compiler. Once installed, the QVM and quilc can be started by\n    running the commands `quilc -S` and `qvm -S` in separate terminal\n    windows.\n\n-   [PennyLane-Rigetti\n    plugin](https://docs.pennylane.ai/projects/rigetti/en/latest/), in\n    order to access the QVM as a PennyLane device. This can be installed\n    via pip:\n\n    ``` {.bash}\n    pip install pennylane-rigetti\n    ```\n\n-   [PennyLane-Braket\n    plugin](https://amazon-braket-pennylane-plugin-python.readthedocs.io/en/latest/),\n    in order to access the Rigetti QPU as a PennyLane device. This can\n    be installed via pip:\n\n    ``` {.bash}\n    pip install amazon-braket-pennylane-plugin\n    ```\n\n-   [PyTorch](https://pytorch.org/get-started/locally/), in order to\n    access the PyTorch QNode interface. Follow the link for instructions\n    on the best way to install PyTorch for your system.\n\nSetting up the device\n---------------------\n\nOnce the dependencies above are installed, let\\'s begin importing the\nrequired packages and setting up our quantum device.\n\nTo start with, we import PennyLane, and, as we are using the PyTorch\ninterface, PyTorch as well:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nimport torch\nfrom torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that we do not need to import the wrapped version of NumPy provided\nby PennyLane, as we are not using the default QNode NumPy interface. If\nNumPy is needed, it is fine to import vanilla NumPy for use with PyTorch\nand TensorFlow.\n\nNext, we will create our device:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"rigetti.qvm\", device=\"2q\", noisy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we create a noisy two-qubit system, simulated via the QVM. If we\nwish, we could also build the model on a physical device, such as the\n`Aspen-M-2` QPU which can be accessed through Amazon Braket (more\ndetails on that will follow).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Constructing the QNode\n======================\n\nNow that we have initialized the device, we can construct our quantum\nnode. Like the other tutorials, we use the\n`~.pennylane.qnode`{.interpreted-text role=\"mod\"} decorator to convert\nour quantum function (encoded by the circuit above) into a quantum node\nrunning on the QVM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, interface=\"torch\")\ndef circuit(phi, theta):\n    qml.RX(theta, wires=0)\n    qml.RZ(phi, wires=0)\n    return qml.expval(qml.PauliZ(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make the QNode \\'PyTorch aware\\', we need to specify that the QNode\ninterfaces with PyTorch. This is done by passing the `interface='torch'`\nkeyword argument.\n\nAs a result, this QNode will be set up to accept and return PyTorch\ntensors, and will also automatically calculate any analytic gradients\nwhen PyTorch performs backpropagation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimization\n============\n\nWe can now create our optimization cost function. To introduce some\nadditional complexity into the system, rather than simply training the\nvariational circuit to \\'flip a qubit\\' from state\n$\\left|0\\right\\rangle$ to state $\\left|1\\right\\rangle$, let\\'s also\nmodify the target state every 100 steps. For example, for the first 100\nsteps, the target state will be $\\left|1\\right\\rangle$; this will then\nchange to $\\left|0\\right\\rangle$ for steps 100 and 200, before changing\nback to state $\\left|1\\right\\rangle$ for steps 200 to 300, and so on.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def cost(phi, theta, step):\n    target = -(-1) ** (step // 100)\n    return torch.abs(circuit(phi, theta) - target) ** 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the cost function is defined, we can begin the PyTorch\noptimization. We create two variables, representing the two free\nparameters of the variational circuit, and initialize an Adam optimizer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "phi = Variable(torch.tensor(1.0), requires_grad=True)\ntheta = Variable(torch.tensor(0.05), requires_grad=True)\nopt = torch.optim.Adam([phi, theta], lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we are using the PyTorch interface, we must use PyTorch optimizers,\n*not* the built-in optimizers provided by PennyLane. The built-in\noptimizers only apply to the default NumPy/autograd interface.\n\nOptimizing the system for 400 steps:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i in range(400):\n    opt.zero_grad()\n    loss = cost(phi, theta, i)\n    loss.backward()\n    opt.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now check the final values of the parameters, as well as the\nfinal circuit output and cost function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(phi)\nprint(theta)\nprint(circuit(phi, theta))\nprint(cost(phi, theta, 400))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\ntensor(-0.7055, requires_grad=True)\ntensor(6.1330, requires_grad=True)\ntensor(0.9551, dtype=torch.float64, grad_fn=<SqueezeBackward0>)\ntensor(3.7162, dtype=torch.float64, grad_fn=<PowBackward0>)\n```\n:::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the cost function is step-dependent, this does not provide enough\ndetail to determine if the optimization was successful; instead, let\\'s\nplot the output state of the circuit over time on a Bloch sphere:\n\n![](../demonstrations/pytorch_noise/bloch.gif){.align-center}\n\nHere, the red x is the target state of the variational circuit, and the\narrow is the variational circuit output state. As the target state\nchanges, the circuit learns to produce the new target state!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hybrid GPU-QPU optimization\n===========================\n\nAs PyTorch natively supports GPU-accelerated classical processing, and\nAmazon Braket provides quantum hardware access in the form of QPUs, we\ncan run the above code as a hybrid GPU-QPU optimization with very little\nmodification.\n\nNote that to run the following script, you will need access to\nRigetti\\'s QPU. To connect to a QPU, we can use Amazon Braket. For a\ndedicated demonstration on using Amazon Braket, see our tutorial on\n[Computing gradients in parallel with Amazon\nBraket](https://pennylane.ai/qml/demos/braket-parallel-gradients.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nimport torch\nfrom torch.autograd import Variable\n\nmy_bucket = \"amazon-braket-Your-Bucket-Name\"  # the name of the bucket\nmy_prefix = \"Your-Folder-Name\"  # the name of the folder in the bucket\ns3_folder = (my_bucket, my_prefix)\n\ndevice_arn = \"arn:aws:braket:us-west-1::device/qpu/rigetti/Aspen-M-2\"\n\nqpu = qml.device(\n    \"braket.aws.qubit\",\n    device_arn=device_arn,\n    wires=32,\n    s3_destination_folder=s3_folder,\n)\n\n# Note: swap dev to qpu here to use the QPU\n# Warning: check the pricing of Aspen-M-2 on Braket to make\n# sure you are aware of the costs associated with running the\n# optimization below.\n@qml.qnode(dev, interface=\"torch\")\ndef circuit(phi, theta):\n    qml.RX(theta, wires=0)\n    qml.RZ(phi, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\n\ndef cost(phi, theta, step):\n    target = -(-1) ** (step // 100)\n    return torch.abs(circuit(phi, theta) - target) ** 2\n\n\nphi = Variable(torch.tensor(1.0, device=\"cuda\"), requires_grad=True)\ntheta = Variable(torch.tensor(0.05, device=\"cuda\"), requires_grad=True)\nopt = torch.optim.Adam([phi, theta], lr=0.1)\n\nfor i in range(400):\n    opt.zero_grad()\n    loss = cost(phi, theta, i)\n    loss.backward()\n    opt.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When using a classical interface that supports GPUs, the QNode will\nautomatically copy any tensor arguments to the CPU, before applying them\non the specified quantum device. Once done, it will return a tensor\ncontaining the QNode result, and automatically copy it back to the GPU\nfor any further classical processing.\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nFor more details on the PyTorch interface, see\n`introduction/interfaces/torch`{.interpreted-text role=\"doc\"}.\n:::\n\nAbout the author\n================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}