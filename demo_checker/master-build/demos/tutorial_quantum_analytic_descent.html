
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta content="Implement the Quantum analytic descent algorithm for VQE." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/flowchart.png" property="og:image" />

  <link rel="icon" type="image/x-icon" href="../_static/favicon.ico">
  <link rel="shortcut icon" type="image/x-icon" href="../_static/favicon.ico">
  


  <meta property="og:title" content="Quantum analytic descent &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_quantum_analytic_descent.html">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Implement the Quantum analytic descent algorithm for VQE." property="og:description" />
  

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto&display=swap">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Material Design Bootstrap -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.5.14/css/mdb.min.css">
  <!-- NanoScroller -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/css/nanoscroller.min.css">
  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/tomorrow-night.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['\\hat{\\mathbf{1}}',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0],
           expect: ["\\langle #1 \\rangle",1],
           pde: ["\\frac{\\partial}{\\partial \#1}",1],
           R: ["\\mathbb{R}",0],
           C: ["\\mathbb{C}",0],
           Ad: ["\\text{Ad}",0],
           Var: ["\\text{Var}",0],
           bx: ["\\mathbf{x}", 0],
           bm: ["\\boldsymbol{\#1}",1],
           haf: ["\\mathrm{haf}",0],
           lhaf: ["\\mathrm{lhaf}",0]
         }
       }
     });
     </script>

  <!-- Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-130507810-1');
      </script>
  
    <title>Quantum analytic descent &#8212; PennyLane  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/light-slider.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/hubs.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_quantum_analytic_descent.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Variationally optimizing measurement protocols" href="tutorial_quantum_metrology.html" />
    <link rel="prev" title="Feedback-Based Quantum Optimization (FALQON)" href="tutorial_falqon.html" /> 
  </head><body><nav class="navbar navbar-expand-lg navbar-light white sticky-top">

<!-- Logo and Title -->









  



  <a class="navbar-brand nav-link" href="https://pennylane.ai">
    
  <img class="pr-1" src=" ../_static/logo.png" width="28px"></img>
  
    <img id="navbar-wordmark" src="../_static/pennylane.svg"></img>
  
  </a>


  <!-- [Mobile] Collapse Button -->
  <div class="row right">
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
      aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>

  <!-- [Mobile] Collapsible Content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links on the Left -->
    <ul class="navbar-nav mr-auto">
      
        
          
            <li class="nav-item active">
              <a class="nav-link" href="https://pennylane.ai/qml/">
                
  
    Learn
  

              </a>
              <span class="sr-only">(current)</span>
            </li>
          

        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/qml/demonstrations.html">
                
  
    Demos
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/install.html">
                
  
    Install
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/plugins.html">
                
  
    Plugins
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://docs.pennylane.ai">
                
  
    Documentation
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/blog/">
                
  
    Blog
  

            </a>
          </li>
        
      
    </ul>

    <!-- Links on the Right -->
    <ul class="navbar-nav ml-auto nav-flex-icons">
      
        <li class="nav-item">
          <a class="nav-link" href="https://pennylane.ai/faq.html">
            <i class="fas fa-question pr-1"></i> FAQ
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://discuss.pennylane.ai/">
            <i class="fab fa-discourse pr-1"></i> Support
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PennyLaneAI/pennylane">
            <i class="fab fa-github pr-1"></i> GitHub
          </a>
        </li>
      

    </ul>
  </div>

</nav>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial_quantum_metrology.html" title="Variationally optimizing measurement protocols"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial_falqon.html" title="Feedback-Based Quantum Optimization (FALQON)"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../demos_optimization.html" accesskey="U">Optimization</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quantum analytic descent</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">
        <div id="content">
          <div id="right-column">
            
            

            <div class="document clearer body">
              
    <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-demos-tutorial-quantum-analytic-descent-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="quantum-analytic-descent">
<span id="sphx-glr-demos-tutorial-quantum-analytic-descent-py"></span><span id="id1"></span><h1>Quantum analytic descent<a class="headerlink" href="#quantum-analytic-descent" title="Permalink to this headline">¶</a></h1>
<p><script type="text/javascript">
    var related_tutorials = ["tutorial_vqe.html", "tutorial_quantum_natural_gradient.html", "tutorial_rotoselect.html", "tutorial_stochastic_parameter_shift.html"];
    var related_tutorials_titles = ['A brief overview of VQE', 'Quantum natural gradient', 'Quantum circuit structure learning', 'The stochastic parameter-shift rule'];
</script></p>
<p><em>Authors: Elies Gil-Fuster, David Wierichs (Xanadu Residents) — Posted: 30 June 2021. Last updated: 18 November 2021</em></p>
<p>One of the main problems of many-body physics is that of finding the ground
state and ground state energy of a given Hamiltonian.
<a class="reference external" href="https://pennylane.ai/qml/demos/tutorial_vqe.html">The Variational Quantum Eigensolver (VQE)</a> combines smart circuit
design with gradient-based optimization to solve this task.
Several practical demonstrations have shown how near-term quantum
devices may be suitable for VQE and other variational quantum algorithms.
One issue for such an approach, though, is that the optimization landscape is
non-convex, so reaching a good enough local minimum quickly requires hundreds or
thousands of update steps. This is problematic because computing gradients of the
cost function on a quantum computer is inefficient when it comes to circuits
with many parameters.</p>
<p>At the same time, we have a good understanding of the <em>local</em> shape
of the cost landscape around any reference point.
Cashing in on this, the authors of the
Quantum Analytic Descent paper <a class="footnote-reference brackets" href="#qad" id="id2">1</a>
propose an algorithm that constructs a classical model which approximates the
landscape, so that the gradients can be calculated on a classical computer, which is much cheaper.
In order to build the classical model, we need to use the quantum device to
evaluate the cost function on (a) a reference point <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span>,
and (b) a number of points shifted away from <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span>.
With the cost values at these points, we can build the classical model that
approximates the landscape.</p>
<p>In this demo, you will learn how to implement Quantum Analytic Descent using PennyLane.
In addition, you will look under the hood of the constructed models and the optimization steps
carried out by the algorithm.
So: sit down, relax, and enjoy your optimization!</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="figure align-center" id="id6">
<a class="reference external image-reference" href="javascript:void(0)"><img alt="../_images/xkcd.png" src="../_images/xkcd.png" style="width: 50%;" /></a>
<p class="caption"><span class="caption-text">Optimization progress with Quantum Analytic Descent.</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="vqes-give-rise-to-trigonometric-cost-functions">
<h2>VQEs give rise to trigonometric cost functions<a class="headerlink" href="#vqes-give-rise-to-trigonometric-cost-functions" title="Permalink to this headline">¶</a></h2>
<p>When we talk about VQEs we have a quantum circuit with <span class="math notranslate nohighlight">\(n\)</span> qubits in mind, which are typically initialized in the base state <span class="math notranslate nohighlight">\(|0\rangle\)</span>.
The body of the circuit is a <em>variational form</em> <span class="math notranslate nohighlight">\(V(\boldsymbol{\theta})\)</span> – a fixed architecture of quantum gates parametrized by an array of real-valued parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\in\mathbb{R}^m\)</span>.
After the variational form, the circuit ends with the measurement of a chosen observable
<span class="math notranslate nohighlight">\(\mathcal{M}\)</span>, based on the problem
we are trying to solve.</p>
<p>The idea in VQE is to fix a variational form such that the expected value of the measurement relates to the energy of an interesting Hamiltonian:</p>
<div class="math notranslate nohighlight">
\[E(\boldsymbol{\theta}) = \langle 0|V^\dagger(\boldsymbol{\theta})\mathcal{M}V(\boldsymbol{\theta})|0\rangle.\]</div>
<p>We want to find the lowest possible energy the system can attain;
this corresponds to running an optimization program to find the <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> that minimizes the function above.</p>
<p>If the gates in the variational form are restricted to be Pauli rotations, then the cost function is a sum of <em>multilinear trigonometric terms</em> in each of the parameters.
That’s a scary sequence of words!
What it means is that if we look at <span class="math notranslate nohighlight">\(E(\boldsymbol{\theta})\)</span> but we focus only on one of the parameters, say <span class="math notranslate nohighlight">\(\theta_i\)</span>, then we can write the functional dependence as a linear combination of three functions: <span class="math notranslate nohighlight">\(1\)</span>, <span class="math notranslate nohighlight">\(\sin(\theta_i)\)</span>, and <span class="math notranslate nohighlight">\(\cos(\theta_i)\)</span>.
That is, for each parameter <span class="math notranslate nohighlight">\(\theta_i\)</span> there exist <span class="math notranslate nohighlight">\(a_i\)</span>, <span class="math notranslate nohighlight">\(b_i\)</span>, and <span class="math notranslate nohighlight">\(c_i\)</span> such that the cost can be written as</p>
<div class="math notranslate nohighlight">
\[E(\boldsymbol{\theta}) = a_i + b_i\sin(\theta_i) + c_i\cos(\theta_i).\]</div>
<p>All parameters but <span class="math notranslate nohighlight">\(\theta_i\)</span> are absorbed in the coefficients <span class="math notranslate nohighlight">\(a_i\)</span>, <span class="math notranslate nohighlight">\(b_i\)</span> and <span class="math notranslate nohighlight">\(c_i\)</span>.
Another technique using this structure of <span class="math notranslate nohighlight">\(E(\boldsymbol{\theta})\)</span> are the
Rotosolve/Rotoselect algorithms <a class="footnote-reference brackets" href="#rotosolve" id="id3">2</a> for which there also is <a class="reference external" href="https://pennylane.ai/qml/demos/tutorial_rotoselect.html">a PennyLane demo</a>.</p>
<p>Let’s look at a toy example to illustrate this structure of the cost function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create a device with 2 qubits.</span>
<span class="n">dev</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Define the variational form V and observable M and combine them into a QNode.</span>
<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;parameter-shift&quot;</span><span class="p">,</span> <span class="n">max_diff</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">circuit</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">):</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RX.html#pennylane.RX" title="pennylane.RX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">RX</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RX.html#pennylane.RX" title="pennylane.RX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">RX</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">@</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>Let us now look at how the energy value depends on each of the two parameters alone.
For that, we just fix one parameter and show the cost when varying the other one:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create 1D sweeps through parameter space with the other parameter fixed.</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Fix a parameter position.</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
<span class="n">C1</span> <span class="o">=</span> <span class="p">[</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">]</span>
<span class="n">C2</span> <span class="o">=</span> <span class="p">[</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">theta</span><span class="p">]))</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">]</span>

<span class="c1"># Show the sweeps.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$E(</span><span class="se">\\</span><span class="s2">theta, 0.5)$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$E(3.3, </span><span class="se">\\</span><span class="s2">theta)$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;$</span><span class="se">\\</span><span class="s2">theta$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$E$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Create a 2D grid and evaluate the energy on the grid points.</span>
<span class="c1"># We cut out a part of the landscape to increase clarity.</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Y</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Z</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t1</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t2</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">):</span>
        <span class="c1"># Cut out the viewer-facing corner</span>
        <span class="k">if</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">-</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t2</span></a><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t1</span></a> <span class="o">**</span> <span class="mi">2</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Z</span></a><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">([</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t1</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t2</span></a><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Y</span></a><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Z</span></a><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="c1"># Show the energy landscape on the grid.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;projection&quot;</span><span class="p">:</span> <span class="s2">&quot;3d&quot;</span><span class="p">},</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">surf</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Y</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Z</span></a><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$E(</span><span class="se">\\</span><span class="s2">theta_1, </span><span class="se">\\</span><span class="s2">theta_2)$&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#209494&quot;</span><span class="p">)</span>
<span class="n">line1</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="n">num_samples</span><span class="p">,</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">,</span>
    <span class="n">C1</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$E(</span><span class="se">\\</span><span class="s2">theta_1, </span><span class="se">\\</span><span class="s2">theta_2^{(0)})$&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
    <span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">line2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">theta_func</span></a><span class="p">,</span>
    <span class="p">[</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="n">num_samples</span><span class="p">,</span>
    <span class="n">C2</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$E(</span><span class="se">\\</span><span class="s2">theta_1^{(0)}, </span><span class="se">\\</span><span class="s2">theta_2)$&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span>
    <span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../_images/sphx_glr_tutorial_quantum_analytic_descent_001.png" srcset="../_images/sphx_glr_tutorial_quantum_analytic_descent_001.png" alt="tutorial quantum analytic descent" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_tutorial_quantum_analytic_descent_002.png" srcset="../_images/sphx_glr_tutorial_quantum_analytic_descent_002.png" alt="tutorial quantum analytic descent" class = "sphx-glr-multi-img"/></li>
</ul>
<p>Of course this is an overly simplified example, but the key take-home message so far is:
<em>if the variational parameters feed into Pauli rotations, the energy landscape is a multilinear combination of trigonometric functions</em>.
What is a good thing about trigonometric functions?
That’s right!
We have studied them since high school and know how their graphs look.</p>
</div>
<div class="section" id="the-qad-strategy">
<h2>The QAD strategy<a class="headerlink" href="#the-qad-strategy" title="Permalink to this headline">¶</a></h2>
<p>By now we know how the energy landscape looks for a small example.
Scaling this up to more parameters would quickly become unfeasible because we need to query a quantum computer for every combination of parameter values.
The secret ingredient of this sauce is that we only need to build an approximate classical model.
Using an approximate classical model has one feature and one bug.
The feature: it is cheap to construct.
The bug: well, it’s only approximate, so we cannot rely on it fully.
And one extra feature (you didn’t see that coming, did you?): if the reference point about which we build the classical model is a true local minimum, then it will be a local minimum of the classical model too.
And that is the key!
Given a reference point, we use the classical model to find a point that’s closer to the true minimum, and then use that point as reference for a new model!
This is what is called Quantum Analytic Descent (QAD), and if you are fine not knowing yet what all the symbols mean, here’s its pseudo-algorithm:</p>
<ol class="arabic simple">
<li><p>Set an initial reference point <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span>.</p></li>
<li><p>Build the model <span class="math notranslate nohighlight">\(\hat{E}(\boldsymbol{\theta})\approx E(\boldsymbol{\theta}_0+\boldsymbol{\theta})\)</span> at this point.</p></li>
<li><p>Find the minimum <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_\text{min}\)</span> of the model.</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0+\boldsymbol{\theta}_\text{min}\)</span> as the new reference point <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span>, go back to Step 2.</p></li>
<li><p>After convergence or a fixed number of models built, output the last minimum <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_\text{opt}=\boldsymbol{\theta}_0+\boldsymbol{\theta}_\text{min}\)</span>.</p></li>
</ol>
</div>
<div class="section" id="computing-a-classical-model">
<h2>Computing a classical model<a class="headerlink" href="#computing-a-classical-model" title="Permalink to this headline">¶</a></h2>
<p>Knowing how the cost looks when restricted to only one parameter (see the plot above), nothing keeps us in theory from constructing a perfect classical model.
The only thing we need to do is write down a general multilinear trigonometric polynomial and determine its coefficients.
Simple, right?
Well, for <span class="math notranslate nohighlight">\(m\)</span> parameters, there would be <span class="math notranslate nohighlight">\(3^m\)</span> coefficients to estimate, which gives us the ever-dreaded exponential scaling.
Although conceptually simple, building an exact model would require exponentially many resources, and that’s a no-go.
What can we do, then?
The authors of QAD propose building an imperfect model.
This makes <em>all</em> the difference—they use a classical model that is accurate only in
a region close to a given reference point, and that delivers good results for the optimization!</p>
<div class="section" id="function-expansions">
<h3>Function expansions<a class="headerlink" href="#function-expansions" title="Permalink to this headline">¶</a></h3>
<p>What do we usually do when we want to approximate something in a region near to a reference point?
Correct!
We use a Taylor expansion!
But what if we told you there is a better option for the case at hand?
In the QAD paper, the authors state that a <em>trigonometric expansion</em> up to second order is already a sound model candidate. Let’s recap such expansions.</p>
<div class="admonition-taylor-expansion-vs-trigonometric-expansion admonition">
<p class="admonition-title">Taylor expansion vs. Trigonometric expansion</p>
<p>In spirit, a trigonometric expansion and a Taylor expansion are not that different: both are linear combinations of some basis functions, where the coefficients of the sum take very specific values usually related to the derivatives of the function we want to approximate.
The difference between Taylor’s and a trigonometric expansion is mainly what basis of functions we take.
In Calculus I we learned that a Taylor series in one variable <span class="math notranslate nohighlight">\(x\)</span> uses the integer powers of the variable namely <span class="math notranslate nohighlight">\(\{1, x, x^2, x^3, \ldots\}\)</span>, in short <span class="math notranslate nohighlight">\(\{x^n\}_{n\in\mathbb{N}}\)</span>:</p>
<div class="math notranslate nohighlight">
\[f_\text{Taylor}(x) = \sum c_n(x-x_0)^n.\]</div>
<p>A trigonometric expansion instead uses a different basis, also for one variable: <span class="math notranslate nohighlight">\(\{1, \sin(x), \cos(x), \sin(2x), \cos(2x), \ldots\}\)</span>, which we could call the set of trigonometric monomials with integer frequency, or in short <span class="math notranslate nohighlight">\(\{\sin(nx),\cos(nx)\}_{n\in\mathbb{N}}\)</span>:</p>
<div class="math notranslate nohighlight">
\[f_\text{Trig}(x) = \sum a_n \cos(n(x-x_0))+ b_n \sin(n(x-x_0)).\]</div>
<p>For higher-dimensional variables we have to take products of the basis functions of each coordinate, i.e., of monomials or trigonometric monomials respectively.
This does lead to an exponentially increasing number of terms, but if we chop the series soon enough it will not get too much out of hand.
The proposal here is to only go up to second order terms, so we are safe.</p>
</div>
</div>
<div class="section" id="expanding-in-adapted-trigonometric-polynomials">
<h3>Expanding in adapted trigonometric polynomials<a class="headerlink" href="#expanding-in-adapted-trigonometric-polynomials" title="Permalink to this headline">¶</a></h3>
<p>One important aspect in which trigonometric series differ from regular
expansions is that there is not a clear separation between what terms
contribute to each order of the expansion (due to the fact that all
derivatives of sine and cosine are non-zero in general).
Because of this, we group the terms by their leading order contribution, and
in the following table write them next to their non-trigonometric analogues.
All chosen trigonometric monomials have leading order coefficient <span class="math notranslate nohighlight">\(1\)</span>
and they all differ in their leading order contribution.</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 70%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Order</p></th>
<th class="head"><p>Trigonometric monomial</p></th>
<th class="head"><p>Taylor monomial</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p><span class="math notranslate nohighlight">\(A(\boldsymbol{\theta})= \prod_{i=1}^m \cos\left(\frac{\theta_i}{2}\right)^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p><span class="math notranslate nohighlight">\(B_k(\boldsymbol{\theta}) = 2\cos\left(\frac{\theta_k}{2}\right)\sin\left(\frac{\theta_k}{2}\right)\prod_{i\neq k} \cos\left(\frac{\theta_i}{2}\right)^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(x_k\)</span></p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p><span class="math notranslate nohighlight">\(C_k(\boldsymbol{\theta}) = 2\sin\left(\frac{\theta_k}{2}\right)^2\prod_{i\neq k} \cos\left(\frac{\theta_i}{2}\right)^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(x_k^2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><span class="math notranslate nohighlight">\(D_{kl}(\boldsymbol{\theta}) = 4\sin\left(\frac{\theta_k}{2}\right)\cos\left(\frac{\theta_k}{2}\right)\sin\left(\frac{\theta_l}{2}\right)\cos\left(\frac{\theta_l}{2}\right)\prod_{i\neq k,l} \cos\left(\frac{\theta_i}{2}\right)^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(x_kx_l\)</span></p></td>
</tr>
</tbody>
</table>
<p>Those are really large terms compared to a Taylor series!
However, you may have noticed all of those terms have large parts in common.
Indeed, we can rewrite the longer ones in a shorter way which is more decent to look at:</p>
<div class="math notranslate nohighlight">
\[\begin{split}B_k(\boldsymbol{\theta}) &amp;= 2\tan\left(\frac{\theta_k}{2}\right)A(\boldsymbol{\theta})\\
C_k(\boldsymbol{\theta}) &amp;= 2\tan\left(\frac{\theta_k}{2}\right)^2 A(\boldsymbol{\theta})\\
D_{kl}(\boldsymbol{\theta}) &amp;= 4\tan\left(\frac{\theta_k}{2}\right)\tan\left(\frac{\theta_l}{2}\right)A(\boldsymbol{\theta})\end{split}\]</div>
<p>With that, we know what type of terms we should expect to encounter in our local classical model:
the model we want to construct is a linear combination of the functions
<span class="math notranslate nohighlight">\(A(\boldsymbol{\theta})\)</span>, <span class="math notranslate nohighlight">\(B_k(\boldsymbol{\theta})\)</span> and <span class="math notranslate nohighlight">\(C_k(\boldsymbol{\theta})\)</span>
for each parameter, and <span class="math notranslate nohighlight">\(D_{kl}(\boldsymbol{\theta})\)</span> for every pair of different parameters <span class="math notranslate nohighlight">\((\theta_k,\theta_l)\)</span>.</p>
</div>
<div class="section" id="computing-the-expansion-coefficients">
<h3>Computing the expansion coefficients<a class="headerlink" href="#computing-the-expansion-coefficients" title="Permalink to this headline">¶</a></h3>
<p>We can now use the derivatives of the function we are approximating to obtain the coefficients of the linear combination.
As the terms we include in the expansion have leading orders <span class="math notranslate nohighlight">\(0\)</span>, <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(2\)</span>, these derivatives are
<span class="math notranslate nohighlight">\(E(\boldsymbol{\theta})\)</span>, <span class="math notranslate nohighlight">\(\partial E(\boldsymbol{\theta})/\partial \theta_k\)</span>,
<span class="math notranslate nohighlight">\(\partial^2 E(\boldsymbol{\theta})/\partial\theta_k^2\)</span>, and <span class="math notranslate nohighlight">\(\partial^2 E(\boldsymbol{\theta})/\partial \theta_k\partial\theta_l\)</span>.
However, the trigonometric polynomials may contain multiple orders in <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>. For example, both
<span class="math notranslate nohighlight">\(A(\boldsymbol{\theta})\)</span> and <span class="math notranslate nohighlight">\(C_k(\boldsymbol{\theta})\)</span> contribute to the second order, so we have to account
for this in the coefficient of <span class="math notranslate nohighlight">\(\partial^2 E(\boldsymbol{\theta})/\partial \theta_k^2\)</span>.
We can name the different coefficients (including the function value itself) accordingly to how we named the terms in the series:</p>
<div class="math notranslate nohighlight">
\[\begin{split}E^{(A)} &amp;= E(\boldsymbol{\theta})\Bigg|_{\boldsymbol{\theta}=0} \\
E^{(B)}_k &amp;= \frac{\partial E(\boldsymbol{\theta})}{\partial\theta_k}\Bigg|_{\boldsymbol{\theta}=0} \\
E^{(C)}_k &amp;= \frac{\partial^2 E(\boldsymbol{\theta})}{\partial\theta_k^2}\Bigg|_{\boldsymbol{\theta}=0} + \frac{1}{2}E(\boldsymbol{\theta})\Bigg|_{\boldsymbol{\theta}=0}\\
E^{(D)}_{kl} &amp;= \frac{\partial^2 E(\boldsymbol{\theta})}{\partial\theta_k\partial\theta_l}\Bigg|_{\boldsymbol{\theta}=0}\end{split}\]</div>
<p>In PennyLane, computing the gradient of a cost function with respect to an array of parameters can be easily done
with the <a class="reference external" href="https://pennylane.ai/qml/glossary/parameter_shift.html">parameter-shift rule</a>.
By iterating the rule, we can obtain the second derivatives – the Hessian (see for example <a class="footnote-reference brackets" href="#higher-order-diff" id="id4">3</a>).
Let us implement a function that does just that and prepares the coefficients <span class="math notranslate nohighlight">\(E^{(A/B/C/D)}\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_model_data</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the coefficients for the classical model, E^(A), E^(B), E^(C), and E^(D).&quot;&quot;&quot;</span>
    <span class="n">num_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="c1"># E_A contains the energy at the reference point</span>
    <span class="n">E_A</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="c1"># E_B contains the gradient.</span>
    <span class="n">E_B</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.grad.html#pennylane.grad" title="pennylane.grad" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">grad</span></a><span class="p">(</span><span class="n">fun</span><span class="p">)(</span><span class="n">params</span><span class="p">)</span>

    <span class="n">hessian</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.jacobian.html#pennylane.jacobian" title="pennylane.jacobian" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">jacobian</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.grad.html#pennylane.grad" title="pennylane.grad" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">grad</span></a><span class="p">(</span><span class="n">fun</span><span class="p">))(</span><span class="n">params</span><span class="p">)</span>

    <span class="c1"># E_C contains the slightly adapted diagonal of the Hessian.</span>
    <span class="n">E_C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">hessian</span><span class="p">)</span> <span class="o">+</span> <span class="n">E_A</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="c1"># E_D contains the off-diagonal parts of the Hessian.</span>
    <span class="c1"># We store each pair (k, l) only once, namely the upper triangle.</span>
    <span class="n">E_D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">hessian</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">E_A</span><span class="p">,</span> <span class="n">E_B</span><span class="p">,</span> <span class="n">E_C</span><span class="p">,</span> <span class="n">E_D</span>
</pre></div>
</div>
<p>Let’s test our brand-new function for the circuit from above, at a random parameter position:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Random parameters (params): </span><span class="si">{</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">coeffs</span> <span class="o">=</span> <span class="n">get_model_data</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Coefficients at params:&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot; E_A = </span><span class="si">{</span><span class="n">coeffs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot; E_B = </span><span class="si">{</span><span class="n">coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot; E_C = </span><span class="si">{</span><span class="n">coeffs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot; E_D = </span><span class="si">{</span><span class="n">coeffs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Random parameters (params): [3.44829694 4.49366732]
Coefficients at params:
 E_A = 0.20685619228992985
 E_B = [-0.06551083 -0.9306212 ]
 E_C = [-0.1034281 -0.1034281]
 E_D = [[0.         0.29472535]
 [0.         0.        ]]
</pre></div>
</div>
</div>
<div class="section" id="the-classical-model-finally">
<h3>The classical model (finally!)<a class="headerlink" href="#the-classical-model-finally" title="Permalink to this headline">¶</a></h3>
<p>Bringing all of the above ingredients together, we have the following gorgeous trigonometric expansion up to second order:</p>
<div class="math notranslate nohighlight">
\[\hat{E}(\boldsymbol{\theta}) := A(\boldsymbol{\theta}) E^{(A)} + \sum_{k=1}^m\left[B_k(\boldsymbol{\theta})E_k^{(B)} + C_k(\boldsymbol{\theta}) E_k^{(C)}\right] + \sum_{k&lt;l}^m\left[D_{kl}(\boldsymbol{\theta}) E_{kl}^{(D)}\right].\]</div>
<p>Let us now take a few moments to breath deeply and admire the entirety of it.
On the one hand, we have the <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B_k\)</span>, <span class="math notranslate nohighlight">\(C_k\)</span>, and
<span class="math notranslate nohighlight">\(D_{kl}\)</span> functions, which we said are the basis functions of the
expansion.
On the other hand we have the real-valued coefficients <span class="math notranslate nohighlight">\(E^{(A/B/C/D)}\)</span> for the previous functions which are nothing but the derivatives in the corresponding input components.
Combining them yields the trigonometric expansion, which we implement with another function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_cost</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">E_A</span><span class="p">,</span> <span class="n">E_B</span><span class="p">,</span> <span class="n">E_C</span><span class="p">,</span> <span class="n">E_D</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the model cost for relative parameters and given model data.&quot;&quot;&quot;</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">params</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># For the other terms we only compute the prefactor relative to A</span>
    <span class="n">B_over_A</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">tan</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">C_over_A</span> <span class="o">=</span> <span class="n">B_over_A</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">D_over_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">B_over_A</span><span class="p">,</span> <span class="n">B_over_A</span><span class="p">)</span>

    <span class="n">all_terms_over_A</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">E_A</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">E_B</span><span class="p">,</span> <span class="n">B_over_A</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">E_C</span><span class="p">,</span> <span class="n">C_over_A</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">B_over_A</span><span class="p">,</span> <span class="n">E_D</span> <span class="o">@</span> <span class="n">B_over_A</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">cost</span> <span class="o">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">all_terms_over_A</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cost</span>


<span class="c1"># Compute the circuit at parameters (This value is also stored in E_A=coeffs[0])</span>
<span class="n">E_original</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">)</span>
<span class="c1"># Compute the model at parameters by plugging in relative parameters 0.</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">E_model</span></a> <span class="o">=</span> <span class="n">model_cost</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">),</span> <span class="o">*</span><span class="n">coeffs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;The cost function at parameters:&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot;  Model:    </span><span class="si">{</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">E_model</span></a><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot;  Original: </span><span class="si">{</span><span class="n">E_original</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># Check that coeffs[0] indeed is the original energy and that the model is correct at 0.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;E_A and E_original are the same: </span><span class="si">{</span><span class="n">coeffs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">E_original</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;E_model and E_original are the same: </span><span class="si">{</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">E_model</span></a><span class="o">==</span><span class="n">E_original</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The cost function at parameters:
  Model:    0.20685619228992985
  Original: 0.20685619228992985
E_A and E_original are the same: True
E_model and E_original are the same: True
</pre></div>
</div>
<p>As we can see, the model reproduces the correct energy at the parameter
position <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span> at which we constructed it (again note how the
input parameters of the model are <em>relative</em> to the reference point
such that <span class="math notranslate nohighlight">\(\hat{E}(0)=E(\boldsymbol{\theta}_0)\)</span> is satisfied).
When we move away from <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span>, the model starts to deviate,
as it is an <em>approximation</em> after all:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Obtain a random shift away from parameters</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shift</span></a> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shift parameters by the vector </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shift</span></a><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">new_parameters</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a> <span class="o">+</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shift</span></a>
<span class="c1"># Compute the cost function and the model at the shifted position.</span>
<span class="n">E_original</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">new_parameters</span></a><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">E_model</span></a> <span class="o">=</span> <span class="n">model_cost</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">shift</span></a><span class="p">,</span> <span class="o">*</span><span class="n">coeffs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;The cost function at parameters:&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot;  Model:    </span><span class="si">{</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">E_model</span></a><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">&quot;  Original: </span><span class="si">{</span><span class="n">E_original</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;E_model and E_original are the same: </span><span class="si">{</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">E_model</span></a><span class="o">==</span><span class="n">E_original</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Shift parameters by the vector [0.0603 0.0545].
The cost function at parameters:
  Model:    0.15256055642369598
  Original: 0.1526096460515975
E_model and E_original are the same: False
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Counting parameters and evaluations</strong></p>
<p>How many parameters does our model have?
In the following table we count them for an <span class="math notranslate nohighlight">\(m\)</span>-dimensional input
variable <span class="math notranslate nohighlight">\(\boldsymbol{\theta}=(\theta_1,\ldots,\theta_m)\)</span>:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 35%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Number of coefficients</p></th>
<th class="head"><p>Number of circuit evaluations</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(E^{(A)}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(E^{(B)}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(m\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(2m\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(E^{(C)}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(m\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(m\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(E^{(D)}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{m(m-1)}{2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(4\frac{m(m-1)}{2}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Total:</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{m^2}{2}+\frac{3m}{2}+1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(2m^2+m+1\)</span></p></td>
</tr>
</tbody>
</table>
<p>So there we go!
We only need polynomially many parameters and circuit evaluations.
This is much cheaper than the <span class="math notranslate nohighlight">\(3^m\)</span> we would need if we naively tried to construct the cost landscape exactly, without chopping after second order.</p>
</div>
<p>Now this should be enough theory, so let’s visualize the model that results from our trigonometric expansion.
We’ll use the coefficients and the <code class="docutils literal notranslate"><span class="pre">model_cost</span></code> function from above and sample a new random parameter position.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="c1"># We actually make the plotting a function because we will reuse it below.</span>
<span class="k">def</span> <span class="nf">plot_cost_and_model</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">shift_radius</span><span class="o">=</span><span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">8</span><span class="p">,</span> <span class="n">num_points</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot a function and a model of the function as well as its deviation.&quot;&quot;&quot;</span>

    <span class="n">coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">shift_radius</span><span class="p">,</span> <span class="n">shift_radius</span><span class="p">,</span> <span class="n">num_points</span><span class="p">)</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Y</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">coords</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">coords</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Compute the original cost function and the model on the grid.</span>
    <span class="n">Z_original</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">f</span><span class="p">(</span><span class="n">params</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t1</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t2</span></a><span class="p">]))</span> <span class="k">for</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t2</span></a> <span class="ow">in</span> <span class="n">coords</span><span class="p">]</span> <span class="k">for</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t1</span></a> <span class="ow">in</span> <span class="n">coords</span><span class="p">])</span>
    <span class="n">Z_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">model</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t1</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t2</span></a><span class="p">]))</span> <span class="k">for</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t2</span></a> <span class="ow">in</span> <span class="n">coords</span><span class="p">]</span> <span class="k">for</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">t1</span></a> <span class="ow">in</span> <span class="n">coords</span><span class="p">])</span>

    <span class="c1"># Prepare sampled points for plotting rods.</span>
    <span class="n">shifts</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="n">shifts</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">shifted_params</span> <span class="o">=</span> <span class="n">params</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">])</span>
        <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="o">*</span><span class="p">(</span><span class="n">params</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s2</span><span class="p">,</span> <span class="n">s1</span><span class="p">])),</span> <span class="n">f</span><span class="p">(</span><span class="n">shifted_params</span><span class="p">)])</span>

    <span class="c1"># Display landscapes incl. sampled points and deviation.</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax0</span><span class="p">,</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;projection&quot;</span><span class="p">:</span> <span class="s2">&quot;3d&quot;</span><span class="p">},</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">green</span> <span class="o">=</span> <span class="s2">&quot;#209494&quot;</span>
    <span class="n">orange</span> <span class="o">=</span> <span class="s2">&quot;#ED7D31&quot;</span>
    <span class="n">red</span> <span class="o">=</span> <span class="s2">&quot;xkcd:brick red&quot;</span>
    <span class="n">surf</span> <span class="o">=</span> <span class="n">ax0</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Y</span></a><span class="p">,</span> <span class="n">Z_original</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">green</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">ax0</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original energy and samples&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Y</span></a><span class="p">,</span> <span class="n">Z_model</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">orange</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Model energy&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Y</span></a><span class="p">,</span> <span class="n">Z_original</span> <span class="o">-</span> <span class="n">Z_model</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">red</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Deviation&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
        <span class="n">ax0</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">Z_original</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">z</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">((</span><span class="n">ax0</span><span class="p">,</span> <span class="n">ax1</span><span class="p">),</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">params</span><span class="p">),</span> <span class="n">model</span><span class="p">(</span><span class="mi">0</span> <span class="o">*</span> <span class="n">params</span><span class="p">))):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">Z_original</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">z</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="n">z</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">w_pad</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>


<span class="c1"># Get some fresh random parameters and the model coefficients</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
<span class="n">coeffs</span> <span class="o">=</span> <span class="n">get_model_data</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">)</span>

<span class="c1"># Define a mapped model that has the model coefficients fixed.</span>
<span class="n">mapped_model</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">params</span><span class="p">:</span> <span class="n">model_cost</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">coeffs</span><span class="p">)</span>
<span class="n">plot_cost_and_model</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">,</span> <span class="n">mapped_model</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quantum_analytic_descent_003.png" srcset="../_images/sphx_glr_tutorial_quantum_analytic_descent_003.png" alt="Original energy and samples, Model energy, Deviation" class = "sphx-glr-single-img"/><p>In the first two plots, we see the true landscape, and the approximate model.
The vertical rods indicate the points at which the original cost function
was evaluated in order to obtain the model coefficients (we skip the additional
evaluations for <span class="math notranslate nohighlight">\(E^{(C)}\)</span>, though, for clarity of the plot).
The rod with the bead on top indicates the reference point around which the model
is built and at which it coincides with the original cost function up to second
order. This is underlined in the third plot, where we see the difference between
the model and true landscapes.
Around the reference point the difference is very small and changes very slowly,
only growing significantly for large simultaneous perturbations in both
parameters. This already hints at the value of the model for local optimization.</p>
</div>
</div>
<div class="section" id="id5">
<h2>Quantum Analytic Descent<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>The underlying idea we will now try to exploit for optimization in VQEs is the following:
if we can model the cost around the reference point well enough, we will be able to find a rough
estimate of where the minimum of the landscape is.
Granted, our model represents the true landscape less accurately the further we go away from the
reference point <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span>, but nonetheless the minimum <em>of the model</em>
will bring us much closer to the minimum <em>of the true cost</em> than a random choice.
Recall the complete strategy from above:</p>
<ol class="arabic simple">
<li><p>Set an initial reference point <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span>.</p></li>
<li><p>Build the model <span class="math notranslate nohighlight">\(\hat{E}(\boldsymbol{\theta})\approx E(\boldsymbol{\theta}_0+\boldsymbol{\theta})\)</span> at this point.</p></li>
<li><p>Find the minimum <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_\text{min}\)</span> of the model.</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0+\boldsymbol{\theta}_\text{min}\)</span> as the new reference point <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_0\)</span>, go back to Step 2.</p></li>
<li><p>After convergence or a fixed number of models built, output the last minimum <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_\text{opt}=\boldsymbol{\theta}_0+\boldsymbol{\theta}_\text{min}\)</span>.</p></li>
</ol>
<p>This provides an iterative strategy which will take us to a good enough solution
in fewer iterations than, for example, regular stochastic gradient descent (SGD).
The procedure of Quantum Analytic Descent is also shown in the following flowchart. Note that the minimization
of the model in Step 3 is carried out via an inner optimization loop.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0)"><img alt="../_images/flowchart.png" src="../_images/flowchart.png" style="width: 80%;" /></a>
</div>
<p>Using the functions from above, we now can implement the loop between Steps 2 and 4.
Indeed, for a relatively small number of iterations we should already find a low enough value.
If we look back at the circuit we defined, we notice that we are measuring the observable</p>
<div class="math notranslate nohighlight">
\[\begin{split}Z\otimes Z=\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; -1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix},\end{split}\]</div>
<p>which has the eigenvalues <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(-1\)</span>.
This means our function is bounded and takes values in the range <span class="math notranslate nohighlight">\([-1,1]\)</span>, so that the global minimum should be around <span class="math notranslate nohighlight">\(-1\)</span> if our circuit is expressive enough.
Let’s try it and apply the full optimization strategy:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>

<span class="c1"># Set the number of iterations of Steps 2, 3, and 4</span>
<span class="n">N_iter_outer</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">N_iter_inner</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">past_coeffs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">past_parameters</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">circuit_log</span> <span class="o">=</span> <span class="p">[</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">)]</span>
<span class="n">model_logs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">iter_outer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_iter_outer</span><span class="p">):</span>
    <span class="c1"># Model building phase of outer iteration - step 2.</span>
    <span class="n">coeffs</span> <span class="o">=</span> <span class="n">get_model_data</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">)</span>
    <span class="n">past_coeffs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">coeffs</span><span class="p">))</span>
    <span class="n">past_parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
    <span class="c1"># Map the model to be only depending on the parameters, not the coefficients.</span>
    <span class="n">mapped_model</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">params</span><span class="p">:</span> <span class="n">model_cost</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">coeffs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">iter_outer</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True energy at initial parameters: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">coeffs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">decimals</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="pennylane.AdamOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">AdamOptimizer</span></a><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="c1"># Recall that the parameters of the model are relative coordinates.</span>
    <span class="c1"># Correspondingly, we initialize at 0, not at parameters.</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">model_log</span> <span class="o">=</span> <span class="p">[</span><span class="n">mapped_model</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;-Iteration </span><span class="si">{</span><span class="n">iter_outer</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">-&quot;</span><span class="p">)</span>

    <span class="c1"># Run the optimizer for N_iter_inner epochs - Step 3.</span>
    <span class="k">for</span> <span class="n">iter_inner</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_iter_inner</span><span class="p">):</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer.step" title="pennylane.AdamOptimizer.step" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-method"><span class="n">opt</span><span class="o">.</span><span class="n">step</span></a><span class="p">(</span><span class="n">mapped_model</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a><span class="p">)</span>
        <span class="n">circuit_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a> <span class="o">+</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a><span class="p">))</span>
        <span class="n">model_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mapped_model</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a><span class="p">))</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">iter_inner</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">E_model</span></a> <span class="o">=</span> <span class="n">mapped_model</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">iter_inner</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">: Model cost = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">E_model</span></a><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot; at relative parameters </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="c1"># Store the relative parameters that minimize the model by adding the shift - Step 4.</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a> <span class="o">+=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">relative_parameters</span></a>
    <span class="n">E_original</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True energy at the minimum of the model: </span><span class="si">{</span><span class="n">E_original</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New reference parameters: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">parameters</span></a><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">model_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_log</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>True energy at initial parameters: 0.5398

-Iteration 1-
Epoch   50: Model cost = -0.7981  at relative parameters [-0.2397  2.0158]
True energy at the minimum of the model: -0.735829672272876
New reference parameters: [2.4222 6.0741]

-Iteration 2-
Epoch   50: Model cost = -1.0084  at relative parameters [0.6908 0.2794]
True energy at the minimum of the model: -0.9971225971605668
New reference parameters: [3.113  6.3535]

-Iteration 3-
Epoch   50: Model cost = -1.0  at relative parameters [ 0.0272 -0.0685]
True energy at the minimum of the model: -0.9999975843757788
New reference parameters: [3.1403 6.285 ]
</pre></div>
</div>
<p>This looks great! Quantum Analytic Descent found the minimum.</p>
<div class="section" id="inspecting-the-models">
<h3>Inspecting the models<a class="headerlink" href="#inspecting-the-models" title="Permalink to this headline">¶</a></h3>
<p>Let us take a look at the intermediate models QAD built:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mapped_model</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">params</span><span class="p">:</span> <span class="n">model_cost</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">past_coeffs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_cost_and_model</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">,</span> <span class="n">mapped_model</span><span class="p">,</span> <span class="n">past_parameters</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quantum_analytic_descent_004.png" srcset="../_images/sphx_glr_tutorial_quantum_analytic_descent_004.png" alt="Original energy and samples, Model energy, Deviation" class = "sphx-glr-single-img"/><p><strong>Iteration 1:</strong> We see the cost function and the model around our starting point. This is the same as the plot before.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mapped_model</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">params</span><span class="p">:</span> <span class="n">model_cost</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">past_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_cost_and_model</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">,</span> <span class="n">mapped_model</span><span class="p">,</span> <span class="n">past_parameters</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quantum_analytic_descent_005.png" srcset="../_images/sphx_glr_tutorial_quantum_analytic_descent_005.png" alt="Original energy and samples, Model energy, Deviation" class = "sphx-glr-single-img"/><p><strong>Iteration 2:</strong> Now we observe the model better resembles the original landscape. In addition, the minimum of the model is within the displayed range – we’re getting closer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mapped_model</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">params</span><span class="p">:</span> <span class="n">model_cost</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">past_coeffs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plot_cost_and_model</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">,</span> <span class="n">mapped_model</span><span class="p">,</span> <span class="n">past_parameters</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quantum_analytic_descent_006.png" srcset="../_images/sphx_glr_tutorial_quantum_analytic_descent_006.png" alt="Original energy and samples, Model energy, Deviation" class = "sphx-glr-single-img"/><p><strong>Iteration 3:</strong> Both the model and the original cost function now show a minimum close to our parameter position— Quantum Analytic Descent converged.
Note how the larger deviations of the model close to the boundaries are not a problem at all because we only use the model in the central area
in which both the original energy and the model form a convex bowl and the deviation plateaus at zero.</p>
</div>
<div class="section" id="optimization-behaviour">
<h3>Optimization behaviour<a class="headerlink" href="#optimization-behaviour" title="Permalink to this headline">¶</a></h3>
<p>If we pay close attention to the values printed during the optimization, we can identify a curious phenomenon.
At the last epochs within some iterations, the <em>model cost</em> goes beyond <span class="math notranslate nohighlight">\(-1\)</span>.
Could we visualize this behavior more clearly, please?</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">circuit_log</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#209494&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_iter_outer</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">N_iter_inner</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">N_iter_inner</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">(</span><span class="n">line</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">model_logs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#ED7D31&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">line</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s2">&quot;Model&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">N_iter_outer</span> <span class="o">*</span> <span class="n">N_iter_inner</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;0.6&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Solution&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;epochs&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;cost&quot;</span><span class="p">)</span>
<span class="n">leg</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quantum_analytic_descent_007.png" srcset="../_images/sphx_glr_tutorial_quantum_analytic_descent_007.png" alt="tutorial quantum analytic descent" class = "sphx-glr-single-img"/><p>Each of the orange lines corresponds to minimizing the model constructed at a
different reference point.
We can now more easily appreciate the phenomenon we just described:
towards the end of each “outer” optimization step, the model cost
can potentially be significantly lower than the true cost.
Once the true cost itself approaches the absolute minimum, this means the
model cost can overstep the allowed range.
<em>Wasn’t this forbidden? You guys told us the function could only take values in</em> <span class="math notranslate nohighlight">\([-1,1]\)</span> &gt;:&#64;
Yes, but careful!
While the <em>true cost</em> values are bounded, that does not mean the ones of the <em>model</em> are!
Notice also how this only happens at the first stages of analytic descent.</p>
<p>Bringing together a few chords we have touched so far: once we fix a reference value, the further we go from it, the less accurate our model becomes.
Thus, if we start far off from the true minimum, it can happen that our model exaggerates how steep the landscape is and then the model minimum lies lower than that of the true cost.
We see how values exiting the allowed range of the true cost function does not have an
impact on the overall optimization.</p>
<p>In this demo we’ve seen how to implement the Quantum Analytic Descent algorithm
using PennyLane for a toy example of a Variational Quantum Eigensolver.
By making extensive use of 3D plots we have also tried to illustrate exactly
what is going on in both the true cost landscape and the trigonometric expansion
approximation.
Recall we wanted to avoid working on the true landscape itself because we can
only access it via very costly quantum computations.
Instead, a fixed number of runs on the quantum device for a few iterations
allowed us to construct a classical model on which we performed (cheap)
classical optimization.</p>
<p>And that was it! Thanks for coming to our show.
Don’t forget to fasten your seat belts on your way home! It was a pleasure
having you here today.</p>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="qad"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>Balint Koczor, Simon Benjamin. “Quantum Analytic Descent”.
<a class="reference external" href="https://arxiv.org/abs/2008.13774">arXiv preprint arXiv:2008.13774</a>.</p>
</dd>
<dt class="label" id="rotosolve"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>Mateusz Ostaszewski, Edward Grant, Marcello Benedetti.
“Structure optimization for parameterized quantum circuits”.
<a class="reference external" href="https://arxiv.org/abs/1905.09692">arXiv preprint arXiv:1905.09692</a>.</p>
</dd>
<dt class="label" id="higher-order-diff"><span class="brackets"><a class="fn-backref" href="#id4">3</a></span></dt>
<dd><p>Andrea Mari, Thomas R. Bromley, Nathan Killoran.
“Estimating the gradient and higher-order derivatives on quantum hardware”.
<a class="reference external" href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.103.012405">Phys. Rev. A 103, 012405</a>, 2021.
<a class="reference external" href="https://arxiv.org/abs/2008.06517">arXiv preprint arXiv:2008.06517</a>.</p>
</dd>
</dl>
</div>
<div class="section" id="about-the-authors">
<h2>About the authors<a class="headerlink" href="#about-the-authors" title="Permalink to this headline">¶</a></h2>
<div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/elies_gil-fuster.jpg" alt="Elies Gil-Fuster" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Elies Gil-Fuster</h4>
        <p class="bio-text__author-description">Elies is a QML researcher in Berlin interested in board games and the maths of data re-uploading PQCs. He was a Xanadu Summer Resident of the first cohort, and you can find more about him at https://eliesgilfuster.eu.</p>
    </div>
</div><div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/david_wierichs.jpg" alt="David Wierichs" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">David Wierichs</h4>
        <p class="bio-text__author-description">David is a researcher and quantum software developer at Xanadu, who likes to think about quantum gradients and how to use them in variational quantum algorithms. He enjoys sharing ideas in science and open source software and likes implementing cool stuff in PennyLane.</p>
    </div>
</div><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  10.987 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-quantum-analytic-descent-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/b28ac977c680782c8b77ebee7eaf11c7/tutorial_quantum_analytic_descent.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_quantum_analytic_descent.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/caaa7ff287287aa75e3752378bed05d3/tutorial_quantum_analytic_descent.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_quantum_analytic_descent.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    <script type="text/javascript">
        // This script ensures that the active navbar entry switches
        // from 'QML' to 'Demos' for any webpage within the demos/ directory,
        // or for any of the demonstration landing pages
        // (e.g., demos_optimization).
        var pagename = document.location.href.match(/[^\/]+$/)[0];
        var dir = document.URL.substr(0,document.URL.lastIndexOf('/')).match(/[^\/]+$/)[0];

        if (pagename.includes("demos") || pagename.includes("demonstrations") || dir.includes("demos")) {

            $(".nav-item.active").removeClass("active");
            var demos_link = $('.navbar-nav a').filter(function(index) { return $(this).text() === "Demos"; })[0]
            $(demos_link).parent().addClass("active");
        }
    </script>

              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_quantum_analytic_descent</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>

            </div>
            
          </div>
        
<div class="localtoc-container nano has-scrollbar">
  <div class="nano-content">
    <div id="localtoc">
        
          <h3>Contents</h3>
          <!-- Display the ToC for the current document if it is not empty. -->
          <ul class='current'>
<li class='current'><a class="reference internal" href="#">Quantum analytic descent</a><ul class='current'>
<li class='current'><a class="reference internal" href="#vqes-give-rise-to-trigonometric-cost-functions">VQEs give rise to trigonometric cost functions</a></li>
<li class='current'><a class="reference internal" href="#the-qad-strategy">The QAD strategy</a></li>
<li class='current'><a class="reference internal" href="#computing-a-classical-model">Computing a classical model</a><ul class='current'>
<li class='current'><a class="reference internal" href="#function-expansions">Function expansions</a></li>
<li class='current'><a class="reference internal" href="#expanding-in-adapted-trigonometric-polynomials">Expanding in adapted trigonometric polynomials</a></li>
<li class='current'><a class="reference internal" href="#computing-the-expansion-coefficients">Computing the expansion coefficients</a></li>
<li class='current'><a class="reference internal" href="#the-classical-model-finally">The classical model (finally!)</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#id5">Quantum Analytic Descent</a><ul class='current'>
<li class='current'><a class="reference internal" href="#inspecting-the-models">Inspecting the models</a></li>
<li class='current'><a class="reference internal" href="#optimization-behaviour">Optimization behaviour</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#references">References</a></li>
<li class='current'><a class="reference internal" href="#about-the-authors">About the authors</a></li>
</ul>
</li>
</ul>

        
    </div>

    <div class="xanadu-call-to-action-links">
        <h3>Downloads</h3>
        <div id="tutorial-type">demos/tutorial_quantum_analytic_descent</div>
        <div class="download-python-link">
            <i class="fab fa-python"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Python script</div>
        </div>
        <div class="download-notebook-link">
            <i class="fas fa-download"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Notebook</div>
        </div>
        <div class="github-view-link">
            <i class="fab fa-github"></i>&nbsp;
            <div class="call-to-action-desktop-view">View on GitHub</div>
        </div>
    </div>
    <div id="related-tutorials" class="mt-4">
      <h3> Related</h3>
    </div>
  </div>
</div>


    
          <div class="up-button">
            
              
                <a href="../demos_optimization.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial_quantum_metrology.html" title="Variationally optimizing measurement protocols"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial_falqon.html" title="Feedback-Based Quantum Optimization (FALQON)"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../demos_optimization.html" >Optimization</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quantum analytic descent</a></li> 
      </ul>
    </div>
  <script type="text/javascript">
    $("#mobile-toggle").click(function () {
      $("#left-column").slideToggle("slow");
    });
  </script>

  <!-- jQuery -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Bootstrap core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <!-- MDB core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
  <!-- NanoScroller -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/javascripts/jquery.nanoscroller.min.js"></script>
  <!-- Syntax Highlighting -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
  <script type="text/javascript">hljs.initHighlightingOnLoad();</script>

  <script type="text/javascript">
    $("a.reference.internal").each(function(){
      var link = $(this).attr("href");

      var hash = link.split("#")[1];
      var page = link.split("#")[0].split("/").slice(-1)[0].replace(".html", "");

      if (hash == page) {
        $(this).attr("href", link.split("#")[0]);
      }
    });

    $(".document > .section").removeClass("section");
    $("h1 ~ .section").removeClass("section");
    $(".localtoc-container .nano-content").css("height", $("#content").height());
    $(".localtoc-container").css("height", $("#content").height());
    $(".nano").nanoScroller();
  </script>

  <script type="text/javascript">
      $(window).scroll(function(){
        var scrollBottom = $(document).height() - $(window).height() - $(window).scrollTop();
        if (scrollBottom < 342) {
          $(".localtoc-container").css("height", "calc(100% - " + (342 - scrollBottom) + "px)");
          $(".localtoc-container .nano-content").css("height", "calc(100% - 119px)");
        }
      });
  </script>

  <script type="text/javascript">
    if ($(".current").length) {
      var target = $(".current")[0]
      var rect = target.getBoundingClientRect();
      if (rect.bottom > window.innerHeight) {
          $(".nano").nanoScroller({ scrollTo: $(".current") });
      } else {
          $(".nano").nanoScroller({ scrollTop: 0 });
      }
    }
    $(document).ready(function () {
        $(".css-transitions-only-after-page-load").each(function (index, element) {
            setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
        });
        if (window.location.hash) {
          var target = $("[id='" + window.location.hash.substr(1) + "']");
          if (target.closest(".collapse").length) {
            target.closest(".collapse").addClass("show");
            target.closest(".collapse").prev().find(".rotate").addClass("up");
          }
        }
    });
  </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "PennyLaneAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href;

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();

    } else {
          $("#related-tutorials").hide();
    }
    </script>

  <!-- Account for MathJax when navigating to anchor tags. -->
  <script type="text/javascript">
    function scrollToElement(e) {
      // Scrolls to the given element, taking into account the navbar.
      MathJax.Hub.Queue(function() {
        // The following MUST be done asynchronously to take effect.
        setTimeout(function() {
          const navbar = document.querySelector("nav.navbar");
          const navbarHeight = navbar ? navbar.offsetHeight : 0;
          const scrollToY = e.offsetTop + e.offsetParent.offsetTop - navbarHeight;
          window.scrollTo(0, scrollToY);
        }, 0);
      });
    }

    function scrollToFragment(fragment) {
      // Scrolls to the position of the given URL fragment (which includes the "#").
      const elementID = fragment.replace(".", "\\.");
      if (elementID !== "") {
        const element = document.querySelector(elementID);
        if (element !== null) {
          scrollToElement(element);
        }
      }
    }

    $(document).ready(() => {
      scrollToFragment(window.location.hash);
      window.addEventListener("popstate", (_) => scrollToFragment(document.location.hash), false);
    });
  </script>

  <!-- Hide the rendering of :orphan: metadata. -->
  <script type="text/javascript">
    $(document).ready(() => {
      const elements = document.getElementsByClassName("field-odd");
      for (const element of elements) {
          if (element.innerHTML.trim() === "orphan") {
            element.style.display = "none";
          }
      }
    });
  </script>

  <script type="text/javascript">
    jQuery.noConflict(true);
  </script>

  

<footer class="page-footer text-md-left pt-4">

  <hr class="pb-0 mb-0">
  <div class="container-fluid">
    <div class="row justify-content-md-center">

      
      <!-- About -->
      <div class="col-md-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <p>        PennyLane is an open-source software framework for quantum
        machine learning, quantum chemistry, and quantum computing, 
        with the ability to run on all hardware.
        Maintained with ❤️ by Xanadu.
        </p>
      </div>
      

      <!-- Links -->
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://pennylane.ai/">Home</a></li>
          
          <li><a href="https://pennylane.ai/qml">Learn</a></li>
          
          <li><a href="https://pennylane.ai/qml/demonstrations.html">Demonstrations</a></li>
          
          <li><a href="https://docs.pennylane.ai/">Documentation</a></li>
          
          <li><a href="https://github.com/PennyLaneAI/pennylane">GitHub</a></li>
          
          <li><a href="https://twitter.com/pennylaneai">Twitter</a></li>
          
          <li><a href="https://pennylane.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">Xanadu</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://xanadu.ai/">Home</a></li>
          
          <li><a href="https://xanadu.ai/about/">About</a></li>
          
          <li><a href="https://xanadu.ai/photonics">Hardware</a></li>
          
          <li><a href="https://xanadu.ai/careers/">Careers</a></li>
          
          <li><a href="https://cloud.xanadu.ai">Cloud</a></li>
          
          <li><a href="https://discuss.pennylane.ai/">Forum</a></li>
          
          <li><a href="https://xanadu.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      

    </div>
  </div>
  <hr>

  <!-- Social -->
  <div class="social-section text-center">
      <ul class="list-unstyled list-inline mb-0">
          
          <li class="list-inline-item"><a class="btn-git" href="https://twitter.com/PennyLaneAI"><i class="fab fa-twitter"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://github.com/PennyLaneAI/pennylane"><i class="fab fa-github"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://discuss.pennylane.ai"><i class="fab fa-discourse"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://xanadu-quantum.slack.com/join/shared_invite/zt-nkwn25v9-H4hituCb_PUj4idG0MhSug#/shared-invite/email"><i class="fab fa-slack"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://pennylane.ai/blog/"><i class="fas fa-rss"> </i></a></li>
          
      </ul>
      
        
          <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">
            Stay updated with our newsletter
          </a>
        
      
  </div>

  <!-- Copyright -->
  <div class="footer-copyright py-3 mt-0 text-center">
      <div class="container-fluid">
            Copyright &copy; 2022, Xanadu Quantum Technologies, Inc.

        
          <br>
          TensorFlow, the TensorFlow logo, and any related marks are trademarks of Google Inc.
        
      </div>
  </div>
</footer>
  </body>
</html>