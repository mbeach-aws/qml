
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta content="Combine PyTorch and PennyLane to train a hybrid quantum-classical image classifier using transfer learning." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/transfer_images.png" property="og:image" />

  <link rel="icon" type="image/x-icon" href="../_static/favicon.ico">
  <link rel="shortcut icon" type="image/x-icon" href="../_static/favicon.ico">
  


  <meta property="og:title" content="Quantum transfer learning &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Combine PyTorch and PennyLane to train a hybrid quantum-classical image classifier using transfer learning." property="og:description" />
  

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto&display=swap">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Material Design Bootstrap -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.5.14/css/mdb.min.css">
  <!-- NanoScroller -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/css/nanoscroller.min.css">
  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/tomorrow-night.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['\\hat{\\mathbf{1}}',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0],
           expect: ["\\langle #1 \\rangle",1],
           pde: ["\\frac{\\partial}{\\partial \#1}",1],
           R: ["\\mathbb{R}",0],
           C: ["\\mathbb{C}",0],
           Ad: ["\\text{Ad}",0],
           Var: ["\\text{Var}",0],
           bx: ["\\mathbf{x}", 0],
           bm: ["\\boldsymbol{\#1}",1],
           haf: ["\\mathrm{haf}",0],
           lhaf: ["\\mathrm{lhaf}",0]
         }
       }
     });
     </script>

  <!-- Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-130507810-1');
      </script>
  
    <title>Quantum transfer learning &#8212; PennyLane  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/light-slider.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/hubs.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Quantum generative adversarial networks with Cirq + TensorFlow" href="tutorial_QGAN.html" />
    <link rel="prev" title="Data-reuploading classifier" href="tutorial_data_reuploading_classifier.html" /> 
  </head><body><nav class="navbar navbar-expand-lg navbar-light white sticky-top">

<!-- Logo and Title -->









  



  <a class="navbar-brand nav-link" href="https://pennylane.ai">
    
  <img class="pr-1" src=" ../_static/logo.png" width="28px"></img>
  
    <img id="navbar-wordmark" src="../_static/pennylane.svg"></img>
  
  </a>


  <!-- [Mobile] Collapse Button -->
  <div class="row right">
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
      aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>

  <!-- [Mobile] Collapsible Content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links on the Left -->
    <ul class="navbar-nav mr-auto">
      
        
          
            <li class="nav-item active">
              <a class="nav-link" href="https://pennylane.ai/qml/">
                
  
    Learn
  

              </a>
              <span class="sr-only">(current)</span>
            </li>
          

        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/qml/demonstrations.html">
                
  
    Demos
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/install.html">
                
  
    Install
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/plugins.html">
                
  
    Plugins
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://docs.pennylane.ai">
                
  
    Documentation
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/blog/">
                
  
    Blog
  

            </a>
          </li>
        
      
    </ul>

    <!-- Links on the Right -->
    <ul class="navbar-nav ml-auto nav-flex-icons">
      
        <li class="nav-item">
          <a class="nav-link" href="https://pennylane.ai/faq.html">
            <i class="fas fa-question pr-1"></i> FAQ
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://discuss.pennylane.ai/">
            <i class="fab fa-discourse pr-1"></i> Support
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PennyLaneAI/pennylane">
            <i class="fab fa-github pr-1"></i> GitHub
          </a>
        </li>
      

    </ul>
  </div>

</nav>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial_QGAN.html" title="Quantum generative adversarial networks with Cirq + TensorFlow"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial_data_reuploading_classifier.html" title="Data-reuploading classifier"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../demos_qml.html" accesskey="U">Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quantum transfer learning</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">
        <div id="content">
          <div id="right-column">
            
            

            <div class="document clearer body">
              
    <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-demos-tutorial-quantum-transfer-learning-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="quantum-transfer-learning">
<span id="sphx-glr-demos-tutorial-quantum-transfer-learning-py"></span><span id="id1"></span><h1>Quantum transfer learning<a class="headerlink" href="#quantum-transfer-learning" title="Permalink to this headline">¶</a></h1>
<p><em>Author: Andrea Mari — Posted: 19 December 2019. Last updated: 28 January 2021.</em></p>
<p>In this tutorial we apply a machine learning method, known as <em>transfer learning</em>, to an
image classifier based on a hybrid classical-quantum network.</p>
<p>This example follows the general structure of the PyTorch
<a class="reference external" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">tutorial on transfer learning</a>
by Sasank Chilamkurthy, with the crucial difference of using a quantum circuit to perform the
final classification task.</p>
<p>More details on this topic can be found in the research paper [1] (<a class="reference external" href="https://arxiv.org/abs/1912.08278">Mari et al. (2019)</a>).</p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Transfer learning is a well-established technique for training artificial neural networks (see e.g., Ref. [2]),
which is based on the general intuition that if a pre-trained network is good at solving a
given problem, then, with just a bit of additional training, it can be used to also solve a different
but related problem.</p>
<p>As discussed in Ref. [1], this idea can be formalized in terms of two abstract networks <span class="math notranslate nohighlight">\(A\)</span>
and <span class="math notranslate nohighlight">\(B\)</span>, independently from their quantum or classical physical nature.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/transfer_learning_general.png"><img alt="transfer_general" src="../_images/transfer_learning_general.png" style="width: 434.7px; height: 287.55px;" /></a>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>As sketched in the above figure, one can give the following <strong>general definition of the
transfer learning method</strong>:</p>
<ol class="arabic simple">
<li><p>Take a network <span class="math notranslate nohighlight">\(A\)</span> that has been pre-trained on a dataset <span class="math notranslate nohighlight">\(D_A\)</span> and for a given
task <span class="math notranslate nohighlight">\(T_A\)</span>.</p></li>
<li><p>Remove some of the final layers. In this way, the resulting truncated network <span class="math notranslate nohighlight">\(A'\)</span>
can be used as a feature extractor.</p></li>
<li><p>Connect a new trainable network <span class="math notranslate nohighlight">\(B\)</span> at the end of the pre-trained network <span class="math notranslate nohighlight">\(A'\)</span>.</p></li>
<li><p>Keep the weights of <span class="math notranslate nohighlight">\(A'\)</span> constant, and train the final block <span class="math notranslate nohighlight">\(B\)</span> with a
new dataset <span class="math notranslate nohighlight">\(D_B\)</span> and/or for a new task of interest <span class="math notranslate nohighlight">\(T_B\)</span>.</p></li>
</ol>
<p>When dealing with hybrid systems, depending on the physical nature (classical or quantum) of the
networks <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, one can have different implementations of transfer learning as</p>
<p>summarized in following table:</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<table class="docstable docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 71%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Network A</p></th>
<th class="head"><p>Network B</p></th>
<th class="head"><p>Transfer learning scheme</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Classical</p></td>
<td><p>Classical</p></td>
<td><p>CC - Standard classical method. See e.g., Ref. [2].</p></td>
</tr>
<tr class="row-odd"><td><p>Classical</p></td>
<td><p>Quantum</p></td>
<td><p>CQ - <strong>Hybrid model presented in this tutorial.</strong></p></td>
</tr>
<tr class="row-even"><td><p>Quantum</p></td>
<td><p>Classical</p></td>
<td><p>QC - Model studied in Ref. [1].</p></td>
</tr>
<tr class="row-odd"><td><p>Quantum</p></td>
<td><p>Quantum</p></td>
<td><p>QQ - Model studied in Ref. [1].</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="classical-to-quantum-transfer-learning">
<h2>Classical-to-quantum transfer learning<a class="headerlink" href="#classical-to-quantum-transfer-learning" title="Permalink to this headline">¶</a></h2>
<p>We focus on the CQ transfer learning scheme discussed in the previous section and we give a specific example.</p>
<ol class="arabic simple">
<li><p>As pre-trained network <span class="math notranslate nohighlight">\(A\)</span> we use <strong>ResNet18</strong>, a deep residual neural network introduced by
Microsoft in Ref. [3], which is pre-trained on the <em>ImageNet</em> dataset.</p></li>
<li><p>After removing its final layer we obtain <span class="math notranslate nohighlight">\(A'\)</span>, a pre-processing block which maps any
input high-resolution image into 512 abstract features.</p></li>
<li><p>Such features are classified by a 4-qubit “dressed quantum circuit” <span class="math notranslate nohighlight">\(B\)</span>, i.e., a
variational quantum circuit sandwiched between two classical layers.</p></li>
<li><p>The hybrid model is trained, keeping <span class="math notranslate nohighlight">\(A'\)</span> constant, on the <em>Hymenoptera</em> dataset
(a small subclass of ImageNet) containing images of <em>ants</em> and <em>bees</em>.</p></li>
</ol>
<p>A graphical representation of the full data processing pipeline is given in the figure below.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/transfer_learning_c2q.png"><img alt="transfer_c2q" src="../_images/transfer_learning_c2q.png" style="width: 664.4000000000001px; height: 115.50000000000001px;" /></a>
</div>
</div>
<div class="section" id="general-setup">
<h2>General setup<a class="headerlink" href="#general-setup" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use the PyTorch interface in PennyLane, you must first
<a class="reference external" href="https://pytorch.org/get-started/locally/#start-locally">install PyTorch</a>.</p>
</div>
<p>In addition to <em>PennyLane</em>, we will also need some standard <em>PyTorch</em> libraries and the
plotting library <em>matplotlib</em>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some parts of this code are based on the Python script:</span>
<span class="c1"># https://github.com/pytorch/tutorials/blob/master/beginner_source/transfer_learning_tutorial.py</span>
<span class="c1"># License: BSD</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="c1"># PyTorch</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">lr_scheduler</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="c1"># Pennylane</span>
<span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># OpenMP: number of parallel threads.</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OMP_NUM_THREADS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="setting-of-the-main-hyper-parameters-of-the-model">
<h2>Setting of the main hyper-parameters of the model<a class="headerlink" href="#setting-of-the-main-hyper-parameters-of-the-model" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To reproduce the results of Ref. [1], <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> should be set to <code class="docutils literal notranslate"><span class="pre">30</span></code> which may take a long time.
We suggest to first try with <code class="docutils literal notranslate"><span class="pre">num_epochs=1</span></code> and, if everything runs smoothly, increase it to a larger value.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_qubits</span> <span class="o">=</span> <span class="mi">4</span>                <span class="c1"># Number of qubits</span>
<span class="n">step</span> <span class="o">=</span> <span class="mf">0.0004</span>               <span class="c1"># Learning rate</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>              <span class="c1"># Number of samples for each training step</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">3</span>              <span class="c1"># Number of training epochs</span>
<span class="n">q_depth</span> <span class="o">=</span> <span class="mi">6</span>                 <span class="c1"># Depth of the quantum circuit (number of variational layers)</span>
<span class="n">gamma_lr_scheduler</span> <span class="o">=</span> <span class="mf">0.1</span>    <span class="c1"># Learning rate reduction applied every 10 epochs.</span>
<span class="n">q_delta</span> <span class="o">=</span> <span class="mf">0.01</span>              <span class="c1"># Initial spread of random quantum weights</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>    <span class="c1"># Start of the computation timer</span>
</pre></div>
</div>
<p>We initialize a PennyLane device with a <code class="docutils literal notranslate"><span class="pre">default.qubit</span></code> backend.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dev</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">n_qubits</span><span class="p">)</span>
</pre></div>
</div>
<p>We configure PyTorch to use CUDA only if available. Otherwise the CPU is used.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dataset-loading">
<h2>Dataset loading<a class="headerlink" href="#dataset-loading" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The dataset containing images of <em>ants</em> and <em>bees</em> can be downloaded
<a class="reference external" href="https://download.pytorch.org/tutorial/hymenoptera_data.zip">here</a> and
should be extracted in the subfolder <code class="docutils literal notranslate"><span class="pre">../_data/hymenoptera_data</span></code>.</p>
</div>
<p>This is a very small dataset (roughly 250 images), too small for training from scratch a
classical or quantum model, however it is enough when using <em>transfer learning</em> approach.</p>
<p>The PyTorch packages <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.utils.data</span></code> are used for loading the dataset
and performing standard preliminary image operations: resize, center, crop, normalize, <em>etc.</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_transforms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="c1"># transforms.RandomResizedCrop(224),     # uncomment for data augmentation</span>
            <span class="c1"># transforms.RandomHorizontalFlip(),     # uncomment for data augmentation</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="c1"># Normalize input channels using mean values and standard deviations of ImageNet.</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
        <span class="p">]</span>
    <span class="p">),</span>
    <span class="s2">&quot;val&quot;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
        <span class="p">]</span>
    <span class="p">),</span>
<span class="p">}</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;../_data/hymenoptera_data&quot;</span>
<span class="n">image_datasets</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">x</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span> <span class="k">else</span> <span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">data_transforms</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">dataset_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">]}</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="n">image_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">classes</span>

<span class="c1"># Initialize dataloader</span>
<span class="n">dataloaders</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># function to plot images</span>
<span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Display image from tensor.&quot;&quot;&quot;</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="c1"># Inverse of the initial normalization operation.</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">std</span> <span class="o">*</span> <span class="n">inp</span> <span class="o">+</span> <span class="n">mean</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
<p>Let us show a batch of the test data, just to have an idea of the classification problem.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get a batch of training data</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]))</span>

<span class="c1"># Make a grid from batch</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="n">class_names</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">])</span>

<span class="n">dataloaders</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quantum_transfer_learning_001.png" srcset="../_images/sphx_glr_tutorial_quantum_transfer_learning_001.png" alt="['bees', 'ants', 'bees', 'bees']" class = "sphx-glr-single-img"/></div>
<div class="section" id="variational-quantum-circuit">
<h2>Variational quantum circuit<a class="headerlink" href="#variational-quantum-circuit" title="Permalink to this headline">¶</a></h2>
<p>We first define some quantum layers that will compose the quantum circuit.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">H_layer</span><span class="p">(</span><span class="n">nqubits</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Layer of single-qubit Hadamard gates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nqubits</span><span class="p">):</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Hadamard.html#pennylane.Hadamard" title="pennylane.Hadamard" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">Hadamard</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">RY_layer</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Layer of parametrized qubit rotations around the y axis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">element</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RY.html#pennylane.RY" title="pennylane.RY" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">RY</span></a><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">entangling_layer</span><span class="p">(</span><span class="n">nqubits</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Layer of CNOTs followed by another shifted layer of CNOT.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># In other words it should apply something like :</span>
    <span class="c1"># CNOT  CNOT  CNOT  CNOT...  CNOT</span>
    <span class="c1">#   CNOT  CNOT  CNOT...  CNOT</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nqubits</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>  <span class="c1"># Loop over even indices: i=0,2,...N-2</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html#pennylane.CNOT" title="pennylane.CNOT" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">CNOT</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nqubits</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>  <span class="c1"># Loop over odd indices:  i=1,3,...N-3</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html#pennylane.CNOT" title="pennylane.CNOT" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">CNOT</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Now we define the quantum circuit through the PennyLane <cite>qnode</cite> decorator .</p>
<p>The structure is that of a typical variational quantum circuit:</p>
<ul class="simple">
<li><p><strong>Embedding layer:</strong> All qubits are first initialized in a balanced superposition
of <em>up</em> and <em>down</em> states, then they are rotated according to the input parameters
(local embedding).</p></li>
<li><p><strong>Variational layers:</strong> A sequence of trainable rotation layers and constant
entangling layers is applied.</p></li>
<li><p><strong>Measurement layer:</strong> For each qubit, the local expectation value of the <span class="math notranslate nohighlight">\(Z\)</span>
operator is measured. This produces a classical output vector, suitable for
additional post-processing.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">quantum_net</span><span class="p">(</span><span class="n">q_input_features</span><span class="p">,</span> <span class="n">q_weights_flat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The variational quantum circuit.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Reshape weights</span>
    <span class="n">q_weights</span> <span class="o">=</span> <span class="n">q_weights_flat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">q_depth</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">)</span>

    <span class="c1"># Start from state |+&gt; , unbiased w.r.t. |0&gt; and |1&gt;</span>
    <span class="n">H_layer</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">)</span>

    <span class="c1"># Embed features in the quantum node</span>
    <span class="n">RY_layer</span><span class="p">(</span><span class="n">q_input_features</span><span class="p">)</span>

    <span class="c1"># Sequence of trainable variational layers</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">q_depth</span><span class="p">):</span>
        <span class="n">entangling_layer</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">)</span>
        <span class="n">RY_layer</span><span class="p">(</span><span class="n">q_weights</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>

    <span class="c1"># Expectation values in the Z basis</span>
    <span class="n">exp_vals</span> <span class="o">=</span> <span class="p">[</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="n">position</span><span class="p">))</span> <span class="k">for</span> <span class="n">position</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">)]</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">exp_vals</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dressed-quantum-circuit">
<h2>Dressed quantum circuit<a class="headerlink" href="#dressed-quantum-circuit" title="Permalink to this headline">¶</a></h2>
<p>We can now define a custom <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> representing a <em>dressed</em> quantum circuit.</p>
<p>This is a concatenation of:</p>
<ul class="simple">
<li><p>A classical pre-processing layer (<code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>).</p></li>
<li><p>A classical activation function (<code class="docutils literal notranslate"><span class="pre">torch.tanh</span></code>).</p></li>
<li><p>A constant <code class="docutils literal notranslate"><span class="pre">np.pi/2.0</span></code> scaling.</p></li>
<li><p>The previously defined quantum circuit (<code class="docutils literal notranslate"><span class="pre">quantum_net</span></code>).</p></li>
<li><p>A classical post-processing layer (<code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>).</p></li>
</ul>
<p>The input of the module is a batch of vectors with 512 real parameters (features) and
the output is a batch of vectors with two real outputs (associated with the two classes
of images: <em>ants</em> and <em>bees</em>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DressedQuantumNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Torch module implementing the *dressed* quantum net.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Definition of the *dressed* layout.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_params</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">q_delta</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">q_depth</span> <span class="o">*</span> <span class="n">n_qubits</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Defining how tensors are supposed to move through the *dressed* quantum</span>
<span class="sd">        net.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># obtain the input features for the quantum circuit</span>
        <span class="c1"># by reducing the feature dimension from 512 to 4</span>
        <span class="n">pre_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_net</span><span class="p">(</span><span class="n">input_features</span><span class="p">)</span>
        <span class="n">q_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">pre_out</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mf">2.0</span>

        <span class="c1"># Apply the quantum circuit to each element of the batch and append to q_out</span>
        <span class="n">q_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">)</span>
        <span class="n">q_out</span> <span class="o">=</span> <span class="n">q_out</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">q_in</span><span class="p">:</span>
            <span class="n">q_out_elem</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">quantum_net</span></a><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_params</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">q_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">q_out</span><span class="p">,</span> <span class="n">q_out_elem</span><span class="p">))</span>

        <span class="c1"># return the two-dimensional prediction from the postprocessing layer</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_net</span><span class="p">(</span><span class="n">q_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="hybrid-classical-quantum-model">
<h2>Hybrid classical-quantum model<a class="headerlink" href="#hybrid-classical-quantum-model" title="Permalink to this headline">¶</a></h2>
<p>We are finally ready to build our full hybrid classical-quantum network.
We follow the <em>transfer learning</em> approach:</p>
<ol class="arabic simple">
<li><p>First load the classical pre-trained network <em>ResNet18</em> from the <code class="docutils literal notranslate"><span class="pre">torchvision.models</span></code> zoo.</p></li>
<li><p>Freeze all the weights since they should not be trained.</p></li>
<li><p>Replace the last fully connected layer with our trainable dressed quantum circuit (<code class="docutils literal notranslate"><span class="pre">DressedQuantumNet</span></code>).</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <em>ResNet18</em> model is automatically downloaded by PyTorch and it may take several minutes (only the first time).</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_hybrid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_hybrid</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>


<span class="c1"># Notice that model_hybrid.fc is the last layer of ResNet18</span>
<span class="n">model_hybrid</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">DressedQuantumNet</span><span class="p">()</span>

<span class="c1"># Use CUDA or CPU according to the &quot;device&quot; object.</span>
<span class="n">model_hybrid</span> <span class="o">=</span> <span class="n">model_hybrid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://download.pytorch.org/models/resnet18-f37072fd.pth&quot; to /home/runner/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth

  0%|          | 0.00/44.7M [00:00&lt;?, ?B/s]
 49%|####9     | 22.0M/44.7M [00:00&lt;00:00, 230MB/s]
100%|##########| 44.7M/44.7M [00:00&lt;00:00, 236MB/s]
</pre></div>
</div>
</div>
<div class="section" id="training-and-results">
<h2>Training and results<a class="headerlink" href="#training-and-results" title="Permalink to this headline">¶</a></h2>
<p>Before training the network we need to specify the <em>loss</em> function.</p>
<p>We use, as usual in classification problem, the <em>cross-entropy</em> which is
directly available within <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
<p>We also initialize the <em>Adam optimizer</em> which is called at each training step
in order to update the weights of the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer_hybrid</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model_hybrid</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
</pre></div>
</div>
<p>We schedule to reduce the learning rate by a factor of <code class="docutils literal notranslate"><span class="pre">gamma_lr_scheduler</span></code>
every 10 epochs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span>
    <span class="n">optimizer_hybrid</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma_lr_scheduler</span>
<span class="p">)</span>
</pre></div>
</div>
<p>What follows is a training function that will be called later.
This function should return a trained model that can be used to make predictions
(classifications).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">since</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">best_loss</span> <span class="o">=</span> <span class="mf">10000.0</span>  <span class="c1"># Large arbitrary number</span>
    <span class="n">best_acc_train</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">best_loss_train</span> <span class="o">=</span> <span class="mf">10000.0</span>  <span class="c1"># Large arbitrary number</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training started:&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

        <span class="c1"># Each epoch has a training and validation phase</span>
        <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
                <span class="c1"># Set model to training mode</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Set model to evaluate mode</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">running_corrects</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Iterate over data.</span>
            <span class="n">n_batches</span> <span class="o">=</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span> <span class="o">//</span> <span class="n">batch_size</span>
            <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                <span class="n">since_batch</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">batch_size_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># Track/compute gradient and make an optimization step only when training</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">):</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
                        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># Print iteration results</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">batch_size_</span>
                <span class="n">batch_corrects</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">running_corrects</span> <span class="o">+=</span> <span class="n">batch_corrects</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Phase: </span><span class="si">{}</span><span class="s2"> Epoch: </span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2"> Iter: </span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2"> Batch time: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">phase</span><span class="p">,</span>
                        <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">num_epochs</span><span class="p">,</span>
                        <span class="n">it</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">n_batches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">since_batch</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Print epoch results</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>
            <span class="n">epoch_acc</span> <span class="o">=</span> <span class="n">running_corrects</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;Phase: </span><span class="si">{}</span><span class="s2"> Epoch: </span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2"> Loss: </span><span class="si">{:.4f}</span><span class="s2"> Acc: </span><span class="si">{:.4f}</span><span class="s2">        &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="s2">&quot;train&quot;</span> <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span> <span class="k">else</span> <span class="s2">&quot;validation  &quot;</span><span class="p">,</span>
                    <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">num_epochs</span><span class="p">,</span>
                    <span class="n">epoch_loss</span><span class="p">,</span>
                    <span class="n">epoch_acc</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Check if this is the best model wrt previous epochs</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;validation&quot;</span> <span class="ow">and</span> <span class="n">epoch_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
                <span class="n">best_acc</span> <span class="o">=</span> <span class="n">epoch_acc</span>
                <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;validation&quot;</span> <span class="ow">and</span> <span class="n">epoch_loss</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span> <span class="ow">and</span> <span class="n">epoch_acc</span> <span class="o">&gt;</span> <span class="n">best_acc_train</span><span class="p">:</span>
                <span class="n">best_acc_train</span> <span class="o">=</span> <span class="n">epoch_acc</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span> <span class="ow">and</span> <span class="n">epoch_loss</span> <span class="o">&lt;</span> <span class="n">best_loss_train</span><span class="p">:</span>
                <span class="n">best_loss_train</span> <span class="o">=</span> <span class="n">epoch_loss</span>

            <span class="c1"># Update learning rate</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Print final results</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_wts</span><span class="p">)</span>
    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">since</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;Training completed in </span><span class="si">{:.0f}</span><span class="s2">m </span><span class="si">{:.0f}</span><span class="s2">s&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time_elapsed</span> <span class="o">//</span> <span class="mi">60</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">%</span> <span class="mi">60</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best test loss: </span><span class="si">{:.4f}</span><span class="s2"> | Best test accuracy: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_loss</span><span class="p">,</span> <span class="n">best_acc</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>We are ready to perform the actual training process.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_hybrid</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span>
    <span class="n">model_hybrid</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_hybrid</span><span class="p">,</span> <span class="n">exp_lr_scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Training started:
Phase: train Epoch: 1/3 Iter: 1/62 Batch time: 0.2509
Phase: train Epoch: 1/3 Iter: 2/62 Batch time: 0.2384
Phase: train Epoch: 1/3 Iter: 3/62 Batch time: 0.2368
Phase: train Epoch: 1/3 Iter: 4/62 Batch time: 0.2330
Phase: train Epoch: 1/3 Iter: 5/62 Batch time: 0.2377
Phase: train Epoch: 1/3 Iter: 6/62 Batch time: 0.2323
Phase: train Epoch: 1/3 Iter: 7/62 Batch time: 0.2336
Phase: train Epoch: 1/3 Iter: 8/62 Batch time: 0.2375
Phase: train Epoch: 1/3 Iter: 9/62 Batch time: 0.2392
Phase: train Epoch: 1/3 Iter: 10/62 Batch time: 0.2411
Phase: train Epoch: 1/3 Iter: 11/62 Batch time: 0.2368
Phase: train Epoch: 1/3 Iter: 12/62 Batch time: 0.2465
Phase: train Epoch: 1/3 Iter: 13/62 Batch time: 0.2391
Phase: train Epoch: 1/3 Iter: 14/62 Batch time: 0.2403
Phase: train Epoch: 1/3 Iter: 15/62 Batch time: 0.2431
Phase: train Epoch: 1/3 Iter: 16/62 Batch time: 0.2409
Phase: train Epoch: 1/3 Iter: 17/62 Batch time: 0.2557
Phase: train Epoch: 1/3 Iter: 18/62 Batch time: 0.2396
Phase: train Epoch: 1/3 Iter: 19/62 Batch time: 0.2643
Phase: train Epoch: 1/3 Iter: 20/62 Batch time: 0.3156
Phase: train Epoch: 1/3 Iter: 21/62 Batch time: 0.3041
Phase: train Epoch: 1/3 Iter: 22/62 Batch time: 0.2699
Phase: train Epoch: 1/3 Iter: 23/62 Batch time: 0.2684
Phase: train Epoch: 1/3 Iter: 24/62 Batch time: 0.2700
Phase: train Epoch: 1/3 Iter: 25/62 Batch time: 0.2620
Phase: train Epoch: 1/3 Iter: 26/62 Batch time: 0.2318
Phase: train Epoch: 1/3 Iter: 27/62 Batch time: 0.2328
Phase: train Epoch: 1/3 Iter: 28/62 Batch time: 0.2362
Phase: train Epoch: 1/3 Iter: 29/62 Batch time: 0.2436
Phase: train Epoch: 1/3 Iter: 30/62 Batch time: 0.2386
Phase: train Epoch: 1/3 Iter: 31/62 Batch time: 0.2391
Phase: train Epoch: 1/3 Iter: 32/62 Batch time: 0.2366
Phase: train Epoch: 1/3 Iter: 33/62 Batch time: 0.2346
Phase: train Epoch: 1/3 Iter: 34/62 Batch time: 0.2354
Phase: train Epoch: 1/3 Iter: 35/62 Batch time: 0.2352
Phase: train Epoch: 1/3 Iter: 36/62 Batch time: 0.2369
Phase: train Epoch: 1/3 Iter: 37/62 Batch time: 0.2343
Phase: train Epoch: 1/3 Iter: 38/62 Batch time: 0.2377
Phase: train Epoch: 1/3 Iter: 39/62 Batch time: 0.2302
Phase: train Epoch: 1/3 Iter: 40/62 Batch time: 0.2370
Phase: train Epoch: 1/3 Iter: 41/62 Batch time: 0.2306
Phase: train Epoch: 1/3 Iter: 42/62 Batch time: 0.2349
Phase: train Epoch: 1/3 Iter: 43/62 Batch time: 0.2376
Phase: train Epoch: 1/3 Iter: 44/62 Batch time: 0.2354
Phase: train Epoch: 1/3 Iter: 45/62 Batch time: 0.2371
Phase: train Epoch: 1/3 Iter: 46/62 Batch time: 0.2379
Phase: train Epoch: 1/3 Iter: 47/62 Batch time: 0.2382
Phase: train Epoch: 1/3 Iter: 48/62 Batch time: 0.2308
Phase: train Epoch: 1/3 Iter: 49/62 Batch time: 0.2310
Phase: train Epoch: 1/3 Iter: 50/62 Batch time: 0.2316
Phase: train Epoch: 1/3 Iter: 51/62 Batch time: 0.2374
Phase: train Epoch: 1/3 Iter: 52/62 Batch time: 0.2344
Phase: train Epoch: 1/3 Iter: 53/62 Batch time: 0.2327
Phase: train Epoch: 1/3 Iter: 54/62 Batch time: 0.2365
Phase: train Epoch: 1/3 Iter: 55/62 Batch time: 0.2346
Phase: train Epoch: 1/3 Iter: 56/62 Batch time: 0.2273
Phase: train Epoch: 1/3 Iter: 57/62 Batch time: 0.2277
Phase: train Epoch: 1/3 Iter: 58/62 Batch time: 0.2356
Phase: train Epoch: 1/3 Iter: 59/62 Batch time: 0.2407
Phase: train Epoch: 1/3 Iter: 60/62 Batch time: 0.2414
Phase: train Epoch: 1/3 Iter: 61/62 Batch time: 0.2330
Phase: train Epoch: 1/3 Loss: 0.6990 Acc: 0.5246
Phase: validation Epoch: 1/3 Iter: 1/39 Batch time: 0.1707
Phase: validation Epoch: 1/3 Iter: 2/39 Batch time: 0.1787
Phase: validation Epoch: 1/3 Iter: 3/39 Batch time: 0.1663
Phase: validation Epoch: 1/3 Iter: 4/39 Batch time: 0.1696
Phase: validation Epoch: 1/3 Iter: 5/39 Batch time: 0.1676
Phase: validation Epoch: 1/3 Iter: 6/39 Batch time: 0.1695
Phase: validation Epoch: 1/3 Iter: 7/39 Batch time: 0.1672
Phase: validation Epoch: 1/3 Iter: 8/39 Batch time: 0.1666
Phase: validation Epoch: 1/3 Iter: 9/39 Batch time: 0.1645
Phase: validation Epoch: 1/3 Iter: 10/39 Batch time: 0.1667
Phase: validation Epoch: 1/3 Iter: 11/39 Batch time: 0.1676
Phase: validation Epoch: 1/3 Iter: 12/39 Batch time: 0.1711
Phase: validation Epoch: 1/3 Iter: 13/39 Batch time: 0.1707
Phase: validation Epoch: 1/3 Iter: 14/39 Batch time: 0.1733
Phase: validation Epoch: 1/3 Iter: 15/39 Batch time: 0.1698
Phase: validation Epoch: 1/3 Iter: 16/39 Batch time: 0.1711
Phase: validation Epoch: 1/3 Iter: 17/39 Batch time: 0.1698
Phase: validation Epoch: 1/3 Iter: 18/39 Batch time: 0.1688
Phase: validation Epoch: 1/3 Iter: 19/39 Batch time: 0.1813
Phase: validation Epoch: 1/3 Iter: 20/39 Batch time: 0.1688
Phase: validation Epoch: 1/3 Iter: 21/39 Batch time: 0.1673
Phase: validation Epoch: 1/3 Iter: 22/39 Batch time: 0.1663
Phase: validation Epoch: 1/3 Iter: 23/39 Batch time: 0.1665
Phase: validation Epoch: 1/3 Iter: 24/39 Batch time: 0.1619
Phase: validation Epoch: 1/3 Iter: 25/39 Batch time: 0.1551
Phase: validation Epoch: 1/3 Iter: 26/39 Batch time: 0.1610
Phase: validation Epoch: 1/3 Iter: 27/39 Batch time: 0.1585
Phase: validation Epoch: 1/3 Iter: 28/39 Batch time: 0.1618
Phase: validation Epoch: 1/3 Iter: 29/39 Batch time: 0.1618
Phase: validation Epoch: 1/3 Iter: 30/39 Batch time: 0.1662
Phase: validation Epoch: 1/3 Iter: 31/39 Batch time: 0.1692
Phase: validation Epoch: 1/3 Iter: 32/39 Batch time: 0.1653
Phase: validation Epoch: 1/3 Iter: 33/39 Batch time: 0.1651
Phase: validation Epoch: 1/3 Iter: 34/39 Batch time: 0.1657
Phase: validation Epoch: 1/3 Iter: 35/39 Batch time: 0.1662
Phase: validation Epoch: 1/3 Iter: 36/39 Batch time: 0.1651
Phase: validation Epoch: 1/3 Iter: 37/39 Batch time: 0.1689
Phase: validation Epoch: 1/3 Iter: 38/39 Batch time: 0.1673
Phase: validation Epoch: 1/3 Iter: 39/39 Batch time: 0.0557
Phase: validation   Epoch: 1/3 Loss: 0.6429 Acc: 0.6536
Phase: train Epoch: 2/3 Iter: 1/62 Batch time: 0.2272
Phase: train Epoch: 2/3 Iter: 2/62 Batch time: 0.2337
Phase: train Epoch: 2/3 Iter: 3/62 Batch time: 0.2299
Phase: train Epoch: 2/3 Iter: 4/62 Batch time: 0.2293
Phase: train Epoch: 2/3 Iter: 5/62 Batch time: 0.2343
Phase: train Epoch: 2/3 Iter: 6/62 Batch time: 0.2258
Phase: train Epoch: 2/3 Iter: 7/62 Batch time: 0.2255
Phase: train Epoch: 2/3 Iter: 8/62 Batch time: 0.2376
Phase: train Epoch: 2/3 Iter: 9/62 Batch time: 0.2477
Phase: train Epoch: 2/3 Iter: 10/62 Batch time: 0.2379
Phase: train Epoch: 2/3 Iter: 11/62 Batch time: 0.2322
Phase: train Epoch: 2/3 Iter: 12/62 Batch time: 0.2170
Phase: train Epoch: 2/3 Iter: 13/62 Batch time: 0.2269
Phase: train Epoch: 2/3 Iter: 14/62 Batch time: 0.2316
Phase: train Epoch: 2/3 Iter: 15/62 Batch time: 0.2324
Phase: train Epoch: 2/3 Iter: 16/62 Batch time: 0.2258
Phase: train Epoch: 2/3 Iter: 17/62 Batch time: 0.2308
Phase: train Epoch: 2/3 Iter: 18/62 Batch time: 0.2302
Phase: train Epoch: 2/3 Iter: 19/62 Batch time: 0.2294
Phase: train Epoch: 2/3 Iter: 20/62 Batch time: 0.2288
Phase: train Epoch: 2/3 Iter: 21/62 Batch time: 0.2285
Phase: train Epoch: 2/3 Iter: 22/62 Batch time: 0.2325
Phase: train Epoch: 2/3 Iter: 23/62 Batch time: 0.2379
Phase: train Epoch: 2/3 Iter: 24/62 Batch time: 0.2537
Phase: train Epoch: 2/3 Iter: 25/62 Batch time: 0.2338
Phase: train Epoch: 2/3 Iter: 26/62 Batch time: 0.2366
Phase: train Epoch: 2/3 Iter: 27/62 Batch time: 0.2317
Phase: train Epoch: 2/3 Iter: 28/62 Batch time: 0.2266
Phase: train Epoch: 2/3 Iter: 29/62 Batch time: 0.2162
Phase: train Epoch: 2/3 Iter: 30/62 Batch time: 0.2244
Phase: train Epoch: 2/3 Iter: 31/62 Batch time: 0.2254
Phase: train Epoch: 2/3 Iter: 32/62 Batch time: 0.2322
Phase: train Epoch: 2/3 Iter: 33/62 Batch time: 0.2361
Phase: train Epoch: 2/3 Iter: 34/62 Batch time: 0.2291
Phase: train Epoch: 2/3 Iter: 35/62 Batch time: 0.2336
Phase: train Epoch: 2/3 Iter: 36/62 Batch time: 0.2409
Phase: train Epoch: 2/3 Iter: 37/62 Batch time: 0.2384
Phase: train Epoch: 2/3 Iter: 38/62 Batch time: 0.2358
Phase: train Epoch: 2/3 Iter: 39/62 Batch time: 0.2330
Phase: train Epoch: 2/3 Iter: 40/62 Batch time: 0.2294
Phase: train Epoch: 2/3 Iter: 41/62 Batch time: 0.2287
Phase: train Epoch: 2/3 Iter: 42/62 Batch time: 0.2341
Phase: train Epoch: 2/3 Iter: 43/62 Batch time: 0.2282
Phase: train Epoch: 2/3 Iter: 44/62 Batch time: 0.2357
Phase: train Epoch: 2/3 Iter: 45/62 Batch time: 0.2198
Phase: train Epoch: 2/3 Iter: 46/62 Batch time: 0.2287
Phase: train Epoch: 2/3 Iter: 47/62 Batch time: 0.2373
Phase: train Epoch: 2/3 Iter: 48/62 Batch time: 0.2388
Phase: train Epoch: 2/3 Iter: 49/62 Batch time: 0.2338
Phase: train Epoch: 2/3 Iter: 50/62 Batch time: 0.2254
Phase: train Epoch: 2/3 Iter: 51/62 Batch time: 0.2289
Phase: train Epoch: 2/3 Iter: 52/62 Batch time: 0.2338
Phase: train Epoch: 2/3 Iter: 53/62 Batch time: 0.2315
Phase: train Epoch: 2/3 Iter: 54/62 Batch time: 0.2293
Phase: train Epoch: 2/3 Iter: 55/62 Batch time: 0.2260
Phase: train Epoch: 2/3 Iter: 56/62 Batch time: 0.2327
Phase: train Epoch: 2/3 Iter: 57/62 Batch time: 0.2292
Phase: train Epoch: 2/3 Iter: 58/62 Batch time: 0.2335
Phase: train Epoch: 2/3 Iter: 59/62 Batch time: 0.2274
Phase: train Epoch: 2/3 Iter: 60/62 Batch time: 0.2290
Phase: train Epoch: 2/3 Iter: 61/62 Batch time: 0.2215
Phase: train Epoch: 2/3 Loss: 0.6134 Acc: 0.7008
Phase: validation Epoch: 2/3 Iter: 1/39 Batch time: 0.1602
Phase: validation Epoch: 2/3 Iter: 2/39 Batch time: 0.1678
Phase: validation Epoch: 2/3 Iter: 3/39 Batch time: 0.1661
Phase: validation Epoch: 2/3 Iter: 4/39 Batch time: 0.1606
Phase: validation Epoch: 2/3 Iter: 5/39 Batch time: 0.1712
Phase: validation Epoch: 2/3 Iter: 6/39 Batch time: 0.1656
Phase: validation Epoch: 2/3 Iter: 7/39 Batch time: 0.1599
Phase: validation Epoch: 2/3 Iter: 8/39 Batch time: 0.1666
Phase: validation Epoch: 2/3 Iter: 9/39 Batch time: 0.1670
Phase: validation Epoch: 2/3 Iter: 10/39 Batch time: 0.1655
Phase: validation Epoch: 2/3 Iter: 11/39 Batch time: 0.1637
Phase: validation Epoch: 2/3 Iter: 12/39 Batch time: 0.1614
Phase: validation Epoch: 2/3 Iter: 13/39 Batch time: 0.1605
Phase: validation Epoch: 2/3 Iter: 14/39 Batch time: 0.1614
Phase: validation Epoch: 2/3 Iter: 15/39 Batch time: 0.1576
Phase: validation Epoch: 2/3 Iter: 16/39 Batch time: 0.1615
Phase: validation Epoch: 2/3 Iter: 17/39 Batch time: 0.1619
Phase: validation Epoch: 2/3 Iter: 18/39 Batch time: 0.1593
Phase: validation Epoch: 2/3 Iter: 19/39 Batch time: 0.1653
Phase: validation Epoch: 2/3 Iter: 20/39 Batch time: 0.1664
Phase: validation Epoch: 2/3 Iter: 21/39 Batch time: 0.1713
Phase: validation Epoch: 2/3 Iter: 22/39 Batch time: 0.1685
Phase: validation Epoch: 2/3 Iter: 23/39 Batch time: 0.1551
Phase: validation Epoch: 2/3 Iter: 24/39 Batch time: 0.1655
Phase: validation Epoch: 2/3 Iter: 25/39 Batch time: 0.1676
Phase: validation Epoch: 2/3 Iter: 26/39 Batch time: 0.1649
Phase: validation Epoch: 2/3 Iter: 27/39 Batch time: 0.1629
Phase: validation Epoch: 2/3 Iter: 28/39 Batch time: 0.1634
Phase: validation Epoch: 2/3 Iter: 29/39 Batch time: 0.1652
Phase: validation Epoch: 2/3 Iter: 30/39 Batch time: 0.1699
Phase: validation Epoch: 2/3 Iter: 31/39 Batch time: 0.1639
Phase: validation Epoch: 2/3 Iter: 32/39 Batch time: 0.1587
Phase: validation Epoch: 2/3 Iter: 33/39 Batch time: 0.1592
Phase: validation Epoch: 2/3 Iter: 34/39 Batch time: 0.1573
Phase: validation Epoch: 2/3 Iter: 35/39 Batch time: 0.1584
Phase: validation Epoch: 2/3 Iter: 36/39 Batch time: 0.1574
Phase: validation Epoch: 2/3 Iter: 37/39 Batch time: 0.1613
Phase: validation Epoch: 2/3 Iter: 38/39 Batch time: 0.1596
Phase: validation Epoch: 2/3 Iter: 39/39 Batch time: 0.0459
Phase: validation   Epoch: 2/3 Loss: 0.5389 Acc: 0.8235
Phase: train Epoch: 3/3 Iter: 1/62 Batch time: 0.2104
Phase: train Epoch: 3/3 Iter: 2/62 Batch time: 0.2211
Phase: train Epoch: 3/3 Iter: 3/62 Batch time: 0.2158
Phase: train Epoch: 3/3 Iter: 4/62 Batch time: 0.2197
Phase: train Epoch: 3/3 Iter: 5/62 Batch time: 0.2170
Phase: train Epoch: 3/3 Iter: 6/62 Batch time: 0.2200
Phase: train Epoch: 3/3 Iter: 7/62 Batch time: 0.2197
Phase: train Epoch: 3/3 Iter: 8/62 Batch time: 0.2249
Phase: train Epoch: 3/3 Iter: 9/62 Batch time: 0.2179
Phase: train Epoch: 3/3 Iter: 10/62 Batch time: 0.2174
Phase: train Epoch: 3/3 Iter: 11/62 Batch time: 0.2199
Phase: train Epoch: 3/3 Iter: 12/62 Batch time: 0.2132
Phase: train Epoch: 3/3 Iter: 13/62 Batch time: 0.2244
Phase: train Epoch: 3/3 Iter: 14/62 Batch time: 0.2244
Phase: train Epoch: 3/3 Iter: 15/62 Batch time: 0.2346
Phase: train Epoch: 3/3 Iter: 16/62 Batch time: 0.2239
Phase: train Epoch: 3/3 Iter: 17/62 Batch time: 0.2191
Phase: train Epoch: 3/3 Iter: 18/62 Batch time: 0.2226
Phase: train Epoch: 3/3 Iter: 19/62 Batch time: 0.2315
Phase: train Epoch: 3/3 Iter: 20/62 Batch time: 0.2326
Phase: train Epoch: 3/3 Iter: 21/62 Batch time: 0.2177
Phase: train Epoch: 3/3 Iter: 22/62 Batch time: 0.2190
Phase: train Epoch: 3/3 Iter: 23/62 Batch time: 0.2212
Phase: train Epoch: 3/3 Iter: 24/62 Batch time: 0.2197
Phase: train Epoch: 3/3 Iter: 25/62 Batch time: 0.2188
Phase: train Epoch: 3/3 Iter: 26/62 Batch time: 0.2192
Phase: train Epoch: 3/3 Iter: 27/62 Batch time: 0.2150
Phase: train Epoch: 3/3 Iter: 28/62 Batch time: 0.2245
Phase: train Epoch: 3/3 Iter: 29/62 Batch time: 0.2178
Phase: train Epoch: 3/3 Iter: 30/62 Batch time: 0.2147
Phase: train Epoch: 3/3 Iter: 31/62 Batch time: 0.2202
Phase: train Epoch: 3/3 Iter: 32/62 Batch time: 0.2321
Phase: train Epoch: 3/3 Iter: 33/62 Batch time: 0.2280
Phase: train Epoch: 3/3 Iter: 34/62 Batch time: 0.2185
Phase: train Epoch: 3/3 Iter: 35/62 Batch time: 0.2257
Phase: train Epoch: 3/3 Iter: 36/62 Batch time: 0.2214
Phase: train Epoch: 3/3 Iter: 37/62 Batch time: 0.2211
Phase: train Epoch: 3/3 Iter: 38/62 Batch time: 0.2210
Phase: train Epoch: 3/3 Iter: 39/62 Batch time: 0.2237
Phase: train Epoch: 3/3 Iter: 40/62 Batch time: 0.2243
Phase: train Epoch: 3/3 Iter: 41/62 Batch time: 0.2214
Phase: train Epoch: 3/3 Iter: 42/62 Batch time: 0.2208
Phase: train Epoch: 3/3 Iter: 43/62 Batch time: 0.2216
Phase: train Epoch: 3/3 Iter: 44/62 Batch time: 0.2237
Phase: train Epoch: 3/3 Iter: 45/62 Batch time: 0.2259
Phase: train Epoch: 3/3 Iter: 46/62 Batch time: 0.2258
Phase: train Epoch: 3/3 Iter: 47/62 Batch time: 0.2264
Phase: train Epoch: 3/3 Iter: 48/62 Batch time: 0.2275
Phase: train Epoch: 3/3 Iter: 49/62 Batch time: 0.2261
Phase: train Epoch: 3/3 Iter: 50/62 Batch time: 0.2405
Phase: train Epoch: 3/3 Iter: 51/62 Batch time: 0.2307
Phase: train Epoch: 3/3 Iter: 52/62 Batch time: 0.2275
Phase: train Epoch: 3/3 Iter: 53/62 Batch time: 0.2663
Phase: train Epoch: 3/3 Iter: 54/62 Batch time: 0.2328
Phase: train Epoch: 3/3 Iter: 55/62 Batch time: 0.2340
Phase: train Epoch: 3/3 Iter: 56/62 Batch time: 0.2350
Phase: train Epoch: 3/3 Iter: 57/62 Batch time: 0.2189
Phase: train Epoch: 3/3 Iter: 58/62 Batch time: 0.2172
Phase: train Epoch: 3/3 Iter: 59/62 Batch time: 0.2169
Phase: train Epoch: 3/3 Iter: 60/62 Batch time: 0.2222
Phase: train Epoch: 3/3 Iter: 61/62 Batch time: 0.2222
Phase: train Epoch: 3/3 Loss: 0.5652 Acc: 0.7418
Phase: validation Epoch: 3/3 Iter: 1/39 Batch time: 0.1636
Phase: validation Epoch: 3/3 Iter: 2/39 Batch time: 0.1625
Phase: validation Epoch: 3/3 Iter: 3/39 Batch time: 0.1633
Phase: validation Epoch: 3/3 Iter: 4/39 Batch time: 0.1688
Phase: validation Epoch: 3/3 Iter: 5/39 Batch time: 0.1560
Phase: validation Epoch: 3/3 Iter: 6/39 Batch time: 0.1551
Phase: validation Epoch: 3/3 Iter: 7/39 Batch time: 0.1609
Phase: validation Epoch: 3/3 Iter: 8/39 Batch time: 0.1583
Phase: validation Epoch: 3/3 Iter: 9/39 Batch time: 0.1606
Phase: validation Epoch: 3/3 Iter: 10/39 Batch time: 0.1655
Phase: validation Epoch: 3/3 Iter: 11/39 Batch time: 0.1653
Phase: validation Epoch: 3/3 Iter: 12/39 Batch time: 0.1657
Phase: validation Epoch: 3/3 Iter: 13/39 Batch time: 0.1660
Phase: validation Epoch: 3/3 Iter: 14/39 Batch time: 0.1645
Phase: validation Epoch: 3/3 Iter: 15/39 Batch time: 0.1652
Phase: validation Epoch: 3/3 Iter: 16/39 Batch time: 0.1672
Phase: validation Epoch: 3/3 Iter: 17/39 Batch time: 0.1620
Phase: validation Epoch: 3/3 Iter: 18/39 Batch time: 0.1557
Phase: validation Epoch: 3/3 Iter: 19/39 Batch time: 0.1620
Phase: validation Epoch: 3/3 Iter: 20/39 Batch time: 0.1635
Phase: validation Epoch: 3/3 Iter: 21/39 Batch time: 0.1553
Phase: validation Epoch: 3/3 Iter: 22/39 Batch time: 0.1610
Phase: validation Epoch: 3/3 Iter: 23/39 Batch time: 0.1569
Phase: validation Epoch: 3/3 Iter: 24/39 Batch time: 0.1567
Phase: validation Epoch: 3/3 Iter: 25/39 Batch time: 0.1597
Phase: validation Epoch: 3/3 Iter: 26/39 Batch time: 0.1557
Phase: validation Epoch: 3/3 Iter: 27/39 Batch time: 0.1588
Phase: validation Epoch: 3/3 Iter: 28/39 Batch time: 0.1589
Phase: validation Epoch: 3/3 Iter: 29/39 Batch time: 0.1577
Phase: validation Epoch: 3/3 Iter: 30/39 Batch time: 0.1650
Phase: validation Epoch: 3/3 Iter: 31/39 Batch time: 0.1645
Phase: validation Epoch: 3/3 Iter: 32/39 Batch time: 0.1575
Phase: validation Epoch: 3/3 Iter: 33/39 Batch time: 0.1573
Phase: validation Epoch: 3/3 Iter: 34/39 Batch time: 0.1665
Phase: validation Epoch: 3/3 Iter: 35/39 Batch time: 0.1662
Phase: validation Epoch: 3/3 Iter: 36/39 Batch time: 0.1701
Phase: validation Epoch: 3/3 Iter: 37/39 Batch time: 0.1677
Phase: validation Epoch: 3/3 Iter: 38/39 Batch time: 0.1587
Phase: validation Epoch: 3/3 Iter: 39/39 Batch time: 0.0474
Phase: validation   Epoch: 3/3 Loss: 0.4484 Acc: 0.8497
Training completed in 1m 9s
Best test loss: 0.4484 | Best test accuracy: 0.8497
</pre></div>
</div>
</div>
<div class="section" id="visualizing-the-model-predictions">
<h2>Visualizing the model predictions<a class="headerlink" href="#visualizing-the-model-predictions" title="Permalink to this headline">¶</a></h2>
<p>We first define a visualization function for a batch of test data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">fig_name</span><span class="o">=</span><span class="s2">&quot;Predictions&quot;</span><span class="p">):</span>
    <span class="n">images_so_far</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">_fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">fig_name</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">_i</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">images_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">num_images</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">images_so_far</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">{}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">preds</span><span class="p">[</span><span class="n">j</span><span class="p">]]))</span>
                <span class="n">imshow</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">images_so_far</span> <span class="o">==</span> <span class="n">num_images</span><span class="p">:</span>
                    <span class="k">return</span>
</pre></div>
</div>
<p>Finally, we can run the previous function to see a batch of images
with the corresponding predictions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_model</span><span class="p">(</span><span class="n">model_hybrid</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quantum_transfer_learning_002.png" srcset="../_images/sphx_glr_tutorial_quantum_transfer_learning_002.png" alt="[ants], [ants], [ants], [ants]" class = "sphx-glr-single-img"/></div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>[1] Andrea Mari, Thomas R. Bromley, Josh Izaac, Maria Schuld, and Nathan Killoran.
<em>Transfer learning in hybrid classical-quantum neural networks</em>. arXiv:1912.08278 (2019).</p>
<p>[2] Rajat Raina, Alexis Battle, Honglak  Lee,  Benjamin Packer, and Andrew Y Ng.
<em>Self-taught learning:  transfer learning from unlabeled data</em>.
Proceedings of the 24th International  Conference  on  Machine  Learning*, 759–766 (2007).</p>
<p>[3] Kaiming He, Xiangyu Zhang, Shaoqing ren and Jian Sun. <em>Deep residual learning for image recognition</em>.
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 770-778 (2016).</p>
<p>[4] Ville Bergholm, Josh Izaac, Maria Schuld, Christian Gogolin, Carsten Blank, Keri McKiernan, and Nathan Killoran.
<em>PennyLane: Automatic differentiation of hybrid quantum-classical computations</em>. arXiv:1811.04968 (2018).</p>
</div>
<div class="section" id="about-the-author">
<h2>About the author<a class="headerlink" href="#about-the-author" title="Permalink to this headline">¶</a></h2>
<div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/andrea_mari.jpeg" alt="Andrea Mari" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Andrea Mari</h4>
        <p class="bio-text__author-description">Andrea obtained a PhD in quantum information theory from the University of Potsdam (Germany). He worked as a postdoc at Scuola Normale Superiore (Pisa, Italy) and as a remote researcher at Xanadu. Since 2020 is a Member of Technical Staff at Unitary Fund.</p>
    </div>
</div><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  10.174 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-quantum-transfer-learning-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/42a469ea5d7ebb2e5283ca4f14e8acce/tutorial_quantum_transfer_learning.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_quantum_transfer_learning.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/298e839618b6866aaace4d226bf7cfae/tutorial_quantum_transfer_learning.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_quantum_transfer_learning.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    <script type="text/javascript">
        // This script ensures that the active navbar entry switches
        // from 'QML' to 'Demos' for any webpage within the demos/ directory,
        // or for any of the demonstration landing pages
        // (e.g., demos_optimization).
        var pagename = document.location.href.match(/[^\/]+$/)[0];
        var dir = document.URL.substr(0,document.URL.lastIndexOf('/')).match(/[^\/]+$/)[0];

        if (pagename.includes("demos") || pagename.includes("demonstrations") || dir.includes("demos")) {

            $(".nav-item.active").removeClass("active");
            var demos_link = $('.navbar-nav a').filter(function(index) { return $(this).text() === "Demos"; })[0]
            $(demos_link).parent().addClass("active");
        }
    </script>

              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_quantum_transfer_learning</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>

            </div>
            
          </div>
        
<div class="localtoc-container nano has-scrollbar">
  <div class="nano-content">
    <div id="localtoc">
        
          <h3>Contents</h3>
          <!-- Display the ToC for the current document if it is not empty. -->
          <ul class='current'>
<li class='current'><a class="reference internal" href="#">Quantum transfer learning</a><ul class='current'>
<li class='current'><a class="reference internal" href="#introduction">Introduction</a></li>
<li class='current'><a class="reference internal" href="#classical-to-quantum-transfer-learning">Classical-to-quantum transfer learning</a></li>
<li class='current'><a class="reference internal" href="#general-setup">General setup</a></li>
<li class='current'><a class="reference internal" href="#setting-of-the-main-hyper-parameters-of-the-model">Setting of the main hyper-parameters of the model</a></li>
<li class='current'><a class="reference internal" href="#dataset-loading">Dataset loading</a></li>
<li class='current'><a class="reference internal" href="#variational-quantum-circuit">Variational quantum circuit</a></li>
<li class='current'><a class="reference internal" href="#dressed-quantum-circuit">Dressed quantum circuit</a></li>
<li class='current'><a class="reference internal" href="#hybrid-classical-quantum-model">Hybrid classical-quantum model</a></li>
<li class='current'><a class="reference internal" href="#training-and-results">Training and results</a></li>
<li class='current'><a class="reference internal" href="#visualizing-the-model-predictions">Visualizing the model predictions</a></li>
<li class='current'><a class="reference internal" href="#references">References</a></li>
<li class='current'><a class="reference internal" href="#about-the-author">About the author</a></li>
</ul>
</li>
</ul>

        
    </div>

    <div class="xanadu-call-to-action-links">
        <h3>Downloads</h3>
        <div id="tutorial-type">demos/tutorial_quantum_transfer_learning</div>
        <div class="download-python-link">
            <i class="fab fa-python"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Python script</div>
        </div>
        <div class="download-notebook-link">
            <i class="fas fa-download"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Notebook</div>
        </div>
        <div class="github-view-link">
            <i class="fab fa-github"></i>&nbsp;
            <div class="call-to-action-desktop-view">View on GitHub</div>
        </div>
    </div>
    <div id="related-tutorials" class="mt-4">
      <h3> Related</h3>
    </div>
  </div>
</div>


    
          <div class="up-button">
            
              
                <a href="../demos_qml.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial_QGAN.html" title="Quantum generative adversarial networks with Cirq + TensorFlow"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial_data_reuploading_classifier.html" title="Data-reuploading classifier"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../demos_qml.html" >Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quantum transfer learning</a></li> 
      </ul>
    </div>
  <script type="text/javascript">
    $("#mobile-toggle").click(function () {
      $("#left-column").slideToggle("slow");
    });
  </script>

  <!-- jQuery -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Bootstrap core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <!-- MDB core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
  <!-- NanoScroller -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/javascripts/jquery.nanoscroller.min.js"></script>
  <!-- Syntax Highlighting -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
  <script type="text/javascript">hljs.initHighlightingOnLoad();</script>

  <script type="text/javascript">
    $("a.reference.internal").each(function(){
      var link = $(this).attr("href");

      var hash = link.split("#")[1];
      var page = link.split("#")[0].split("/").slice(-1)[0].replace(".html", "");

      if (hash == page) {
        $(this).attr("href", link.split("#")[0]);
      }
    });

    $(".document > .section").removeClass("section");
    $("h1 ~ .section").removeClass("section");
    $(".localtoc-container .nano-content").css("height", $("#content").height());
    $(".localtoc-container").css("height", $("#content").height());
    $(".nano").nanoScroller();
  </script>

  <script type="text/javascript">
      $(window).scroll(function(){
        var scrollBottom = $(document).height() - $(window).height() - $(window).scrollTop();
        if (scrollBottom < 342) {
          $(".localtoc-container").css("height", "calc(100% - " + (342 - scrollBottom) + "px)");
          $(".localtoc-container .nano-content").css("height", "calc(100% - 119px)");
        }
      });
  </script>

  <script type="text/javascript">
    if ($(".current").length) {
      var target = $(".current")[0]
      var rect = target.getBoundingClientRect();
      if (rect.bottom > window.innerHeight) {
          $(".nano").nanoScroller({ scrollTo: $(".current") });
      } else {
          $(".nano").nanoScroller({ scrollTop: 0 });
      }
    }
    $(document).ready(function () {
        $(".css-transitions-only-after-page-load").each(function (index, element) {
            setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
        });
        if (window.location.hash) {
          var target = $("[id='" + window.location.hash.substr(1) + "']");
          if (target.closest(".collapse").length) {
            target.closest(".collapse").addClass("show");
            target.closest(".collapse").prev().find(".rotate").addClass("up");
          }
        }
    });
  </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "PennyLaneAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href;

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();

    } else {
          $("#related-tutorials").hide();
    }
    </script>

  <!-- Account for MathJax when navigating to anchor tags. -->
  <script type="text/javascript">
    function scrollToElement(e) {
      // Scrolls to the given element, taking into account the navbar.
      MathJax.Hub.Queue(function() {
        // The following MUST be done asynchronously to take effect.
        setTimeout(function() {
          const navbar = document.querySelector("nav.navbar");
          const navbarHeight = navbar ? navbar.offsetHeight : 0;
          const scrollToY = e.offsetTop + e.offsetParent.offsetTop - navbarHeight;
          window.scrollTo(0, scrollToY);
        }, 0);
      });
    }

    function scrollToFragment(fragment) {
      // Scrolls to the position of the given URL fragment (which includes the "#").
      const elementID = fragment.replace(".", "\\.");
      if (elementID !== "") {
        const element = document.querySelector(elementID);
        if (element !== null) {
          scrollToElement(element);
        }
      }
    }

    $(document).ready(() => {
      scrollToFragment(window.location.hash);
      window.addEventListener("popstate", (_) => scrollToFragment(document.location.hash), false);
    });
  </script>

  <!-- Hide the rendering of :orphan: metadata. -->
  <script type="text/javascript">
    $(document).ready(() => {
      const elements = document.getElementsByClassName("field-odd");
      for (const element of elements) {
          if (element.innerHTML.trim() === "orphan") {
            element.style.display = "none";
          }
      }
    });
  </script>

  <script type="text/javascript">
    jQuery.noConflict(true);
  </script>

  

<footer class="page-footer text-md-left pt-4">

  <hr class="pb-0 mb-0">
  <div class="container-fluid">
    <div class="row justify-content-md-center">

      
      <!-- About -->
      <div class="col-md-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <p>        PennyLane is an open-source software framework for quantum
        machine learning, quantum chemistry, and quantum computing, 
        with the ability to run on all hardware.
        Maintained with ❤️ by Xanadu.
        </p>
      </div>
      

      <!-- Links -->
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://pennylane.ai/">Home</a></li>
          
          <li><a href="https://pennylane.ai/qml">Learn</a></li>
          
          <li><a href="https://pennylane.ai/qml/demonstrations.html">Demonstrations</a></li>
          
          <li><a href="https://docs.pennylane.ai/">Documentation</a></li>
          
          <li><a href="https://github.com/PennyLaneAI/pennylane">GitHub</a></li>
          
          <li><a href="https://twitter.com/pennylaneai">Twitter</a></li>
          
          <li><a href="https://pennylane.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">Xanadu</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://xanadu.ai/">Home</a></li>
          
          <li><a href="https://xanadu.ai/about/">About</a></li>
          
          <li><a href="https://xanadu.ai/photonics">Hardware</a></li>
          
          <li><a href="https://xanadu.ai/careers/">Careers</a></li>
          
          <li><a href="https://cloud.xanadu.ai">Cloud</a></li>
          
          <li><a href="https://discuss.pennylane.ai/">Forum</a></li>
          
          <li><a href="https://xanadu.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      

    </div>
  </div>
  <hr>

  <!-- Social -->
  <div class="social-section text-center">
      <ul class="list-unstyled list-inline mb-0">
          
          <li class="list-inline-item"><a class="btn-git" href="https://twitter.com/PennyLaneAI"><i class="fab fa-twitter"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://github.com/PennyLaneAI/pennylane"><i class="fab fa-github"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://discuss.pennylane.ai"><i class="fab fa-discourse"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://xanadu-quantum.slack.com/join/shared_invite/zt-nkwn25v9-H4hituCb_PUj4idG0MhSug#/shared-invite/email"><i class="fab fa-slack"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://pennylane.ai/blog/"><i class="fas fa-rss"> </i></a></li>
          
      </ul>
      
        
          <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">
            Stay updated with our newsletter
          </a>
        
      
  </div>

  <!-- Copyright -->
  <div class="footer-copyright py-3 mt-0 text-center">
      <div class="container-fluid">
            Copyright &copy; 2022, Xanadu Quantum Technologies, Inc.

        
          <br>
          TensorFlow, the TensorFlow logo, and any related marks are trademarks of Google Inc.
        
      </div>
  </div>
</footer>
  </body>
</html>