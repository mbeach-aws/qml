{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Doubly stochastic gradient descent\n==================================\n\n::: {.meta}\n:property=\\\"og:description\\\": Minimize a Hamiltonian via an adaptive\nshot optimization strategy with doubly stochastic gradient descent.\n:property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/single_shot.png>\n:::\n\n::: {.related}\ntutorial\\_backprop Quantum gradients with backpropagation\ntutorial\\_quantum\\_natural\\_gradient Quantum natural gradient\ntutorial\\_rosalin Frugal shot optimization with Rosalin\n:::\n\n*Author: Josh Izaac --- Posted: 16 October 2019. Last updated: 20\nJanuary 2021.*\n\nIn this tutorial we investigate and implement the doubly stochastic\ngradient descent paper from [Ryan Sweke et al.\n(2019)](https://arxiv.org/abs/1910.01155). In this paper, it is shown\nthat quantum gradient descent, where a finite number of measurement\nsamples (or *shots*) are used to estimate the gradient, is a form of\nstochastic gradient descent. Furthermore, if the optimization involves a\nlinear combination of expectation values (such as VQE), sampling from\nthe terms in this linear combination can further reduce required\nresources, allowing for \\\"doubly stochastic gradient descent\\\".\n\nNote that based on very similar observations, [Jonas Kuebler et al.\n(2019)](https://arxiv.org/abs/1909.09083) recently proposed an optimizer\n(which they call the *individual Coupled Adaptive Number of Shots\n(iCANS)* optimizer) that adapts the shot number of measurements during\ntraining.\n\nBackground\n----------\n\nIn classical machine learning, [stochastic gradient\ndescent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) is a\ncommon optimization strategy where the standard gradient descent\nparameter update rule,\n\n$$\\theta^{(t+1)} = \\theta^{(t)} - \\eta \\nabla \\mathcal{L}(\\theta^{(t)}),$$\n\nis modified such that\n\n$$\\theta^{(t+1)} = \\theta^{(t)} - \\eta g^{(t)}(\\theta^{(t)})$$\n\nwhere $\\eta$ is the step-size, and $\\{g^{(t)}(\\theta)\\}$ is a sequence\nof random variables such that\n\n$$\\mathbb{E}[g^{(t)}(\\theta)] = \\nabla\\mathcal{L}(\\theta).$$\n\nIn general, stochastic gradient descent is preferred over standard\ngradient descent for several reasons:\n\n1.  Samples of the gradient estimator $g^{(t)}(\\theta)$ can typically be\n    computed much more efficiently than $\\mathcal{L}(\\theta)$,\n2.  Stochasticity can help to avoid local minima and saddle points,\n3.  Numerical evidence shows that convergence properties are superior to\n    regular gradient descent.\n\nIn variational quantum algorithms, a parametrized quantum circuit\n$U(\\theta)$ is optimized by a classical optimization loop in order to\nminimize a function of the expectation values. For example, consider the\nexpectation values\n\n$$\\langle A_i \\rangle = \\langle 0 | U(\\theta)^\\dagger A_i U(\\theta) | 0\\rangle$$\n\nfor a set of observables $\\{A_i\\}$, and loss function\n\n$$\\mathcal{L}(\\theta, \\langle A_1 \\rangle, \\dots, \\langle A_M \\rangle).$$\n\nWhile the expectation values can be calculated analytically in classical\nsimulations, on quantum hardware we are limited to *sampling* from the\nexpectation values; as the number of samples (or shots) increase, we\nconverge on the analytic expectation value, but can never recover the\nexact expression. Furthermore, the parameter-shift rule ([Schuld et al.,\n2018](https://arxiv.org/abs/1811.11184)) allows for analytic quantum\ngradients to be computed from a linear combination of the variational\ncircuits\\' expectation values.\n\nPutting these two results together, [Sweke et al.\n(2019)](https://arxiv.org/abs/1910.01155) show that samples of the\nexpectation value fed into the parameter-shift rule provide unbiased\nestimators of the quantum gradient---resulting in a form of stochastic\ngradient descent (referred to as QSGD). Moreover, they show that\nconvergence of the stochastic gradient descent is guaranteed in\nsufficiently simplified settings, even in the case where the number of\nshots is 1!\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nIt is worth noting that the smaller the number of shots used, the larger\nthe variance in the estimated expectation value. As a result, it may\ntake more optimization steps for convergence than using a larger number\nof shots, or an exact value.\n\nAt the same time, a reduced number of shots may significantly reduce the\nwall time of each optimization step, leading to a reduction in the\noverall optimization time.\n:::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\\'s consider a simple example in PennyLane, comparing analytic\ngradient descent (with exact expectation values) to stochastic gradient\ndescent using a finite number of shots.\n\nA single-shot stochastic gradient descent\n=========================================\n\nConsider the Hamiltonian\n\n$$\\begin{aligned}\nH = \\begin{bmatrix}\n      8 & 4 & 0 & -6\\\\\n      4 & 0 & 4 & 0\\\\\n      0 & 4 & 8 & 0\\\\\n      -6 & 0 & 0 & 0\n    \\end{bmatrix}.\n\\end{aligned}$$\n\nWe can solve for the ground state energy using the variational quantum\neigensolver (VQE) algorithm.\n\nLet\\'s use the `lightning.qubit` simulator for both the analytic\ngradient, as well as the estimated gradient using number of shots\n$N\\in\\{1, 100\\}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nfrom pennylane import numpy as np\n\nnp.random.seed(3)\n\nfrom pennylane import expval\nfrom pennylane.templates.layers import StronglyEntanglingLayers\n\nnum_layers = 2\nnum_wires = 2\neta = 0.01\nsteps = 200\n\ndev_analytic = qml.device(\"lightning.qubit\", wires=num_wires, shots=None)\ndev_stochastic = qml.device(\"lightning.qubit\", wires=num_wires, shots=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use `qml.Hermitian` to directly specify that we want to measure\nthe expectation value of the matrix $H$:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "H = np.array([[8, 4, 0, -6], [4, 0, 4, 0], [0, 4, 8, 0], [-6, 0, 0, 0]], requires_grad=False)\n\n\ndef circuit(params):\n    StronglyEntanglingLayers(weights=params, wires=[0, 1])\n    return expval(qml.Hermitian(H, wires=[0, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we create three QNodes, each corresponding to a device above, and\noptimize them using gradient descent via the parameter-shift rule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "qnode_analytic = qml.QNode(circuit, dev_analytic, interface=\"autograd\")\nqnode_stochastic = qml.QNode(circuit, dev_stochastic, interface=\"autograd\")\n\nparam_shape = StronglyEntanglingLayers.shape(n_layers=num_layers, n_wires=num_wires)\ninit_params = np.random.uniform(low=0, high=2*np.pi, size=param_shape, requires_grad=True)\n\n# Optimizing using exact gradient descent\n\ncost_GD = []\nparams_GD = init_params\nopt = qml.GradientDescentOptimizer(eta)\n\nfor _ in range(steps):\n    cost_GD.append(qnode_analytic(params_GD))\n    params_GD = opt.step(qnode_analytic, params_GD)\n\n# Optimizing using stochastic gradient descent with shots=1\n\ndev_stochastic.shots = 1\ncost_SGD1 = []\nparams_SGD1 = init_params\nopt = qml.GradientDescentOptimizer(eta)\n\nfor _ in range(steps):\n    cost_SGD1.append(qnode_stochastic(params_SGD1))\n    params_SGD1 = opt.step(qnode_stochastic, params_SGD1)\n\n# Optimizing using stochastic gradient descent with shots=100\n\ndev_stochastic.shots = 100\ncost_SGD100 = []\nparams_SGD100 = init_params\nopt = qml.GradientDescentOptimizer(eta)\n\nfor _ in range(steps):\n    cost_SGD100.append(qnode_stochastic(params_SGD100))\n    params_SGD100 = opt.step(qnode_stochastic, params_SGD100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that in the latter two cases we are sampling from an unbiased\nestimator of the cost function, not the analytic cost function.\n\nTo track optimization convergence, approaches could include:\n\n-   Evaluating the cost function with a larger number of samples at\n    specified intervals,\n-   Keeping track of the *moving average* of the low-shot cost\n    evaluations.\n\nWe can now plot the cost against optimization step for the three cases\nabove.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n\nplt.style.use(\"seaborn\")\nplt.plot(cost_GD[:100], label=\"Vanilla gradient descent\")\nplt.plot(cost_SGD100[:100], \"--\", label=\"QSGD (100 shots)\")\nplt.plot(cost_SGD1[:100], \".\", label=\"QSGD (1 shot)\")\n\n# analytic ground state\nmin_energy = min(np.linalg.eigvalsh(H))\nplt.hlines(min_energy, 0, 100, linestyles=\":\", label=\"Ground-state energy\")\n\nplt.ylabel(\"Cost function value\")\nplt.xlabel(\"Optimization steps\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the trained parameters from each optimization strategy, we can\nevaluate the analytic quantum device:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Vanilla gradient descent min energy = \", qnode_analytic(params_GD))\nprint(\n    \"Stochastic gradient descent (shots=100) min energy = \",\n    qnode_analytic(params_SGD100),\n)\nprint(\n    \"Stochastic gradient descent (shots=1) min energy = \", qnode_analytic(params_SGD1)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Amazingly, we see that even the `shots=1` optimization converged to a\nreasonably close approximation of the ground-state energy!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Doubly stochastic gradient descent for VQE\n==========================================\n\nAs noted in [Sweke et al. (2019)](https://arxiv.org/abs/1910.01155),\nvariational quantum algorithms often include terms consisting of linear\ncombinations of expectation values. This is true of the parameter-shift\nrule (where the gradient of each parameter is determined by shifting the\nparameter by macroscopic amounts and taking the difference), as well as\nVQE, where the Hamiltonian is usually decomposed into a sum of Pauli\nexpectation values.\n\nConsider the Hamiltonian from the previous section. As this Hamiltonian\nis a Hermitian observable, we can always express it as a sum of Pauli\nmatrices using the relation\n\n$$H = \\sum_{i,j=0,1,2,3} a_{i,j} (\\sigma_i\\otimes \\sigma_j),$$\n\nwhere\n\n$$a_{i,j} = \\frac{1}{4}\\text{tr}[(\\sigma_i\\otimes \\sigma_j )H], ~~ \\sigma = \\{I, X, Y, Z\\}.$$\n\nApplying this, we can see that\n\n$$H = 4  + 2I\\otimes X + 4I \\otimes Z - X\\otimes X + 5 Y\\otimes Y + 2Z\\otimes X.$$\n\nTo perform \\\"doubly stochastic\\\" gradient descent, we simply apply the\nstochastic gradient descent approach from above, but in addition also\nuniformly sample a subset of the terms for the Hamiltonian expectation\nat each optimization step. This inserts another element of stochasticity\ninto the system---all the while convergence continues to be guaranteed!\n\nLet\\'s create a QNode that randomly samples a single term from the above\nHamiltonian as the observable to be measured.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "I = np.identity(2)\nX = np.array([[0, 1], [1, 0]])\nY = np.array([[0, -1j], [1j, 0]])\nZ = np.array([[1, 0], [0, -1]])\n\nterms = np.array(\n    [\n        2 * np.kron(I, X),\n        4 * np.kron(I, Z),\n        -np.kron(X, X),\n        5 * np.kron(Y, Y),\n        2 * np.kron(Z, X),\n    ], requires_grad=False\n)\n\n\n@qml.qnode(dev_stochastic, interface=\"autograd\")\ndef circuit(params, n=None):\n    StronglyEntanglingLayers(weights=params, wires=[0, 1])\n    idx = np.random.choice(np.arange(5), size=n, replace=False)\n    A = np.sum(terms[idx], axis=0)\n    return expval(qml.Hermitian(A, wires=[0, 1]))\n\n\ndef loss(params):\n    return 4 + (5 / 1) * circuit(params, n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimizing the circuit using gradient descent via the parameter-shift\nrule:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev_stochastic.shots = 100\ncost = []\nparams = init_params\nopt = qml.GradientDescentOptimizer(0.005)\n\nfor _ in range(250):\n    cost.append(loss(params))\n    params = opt.step(loss, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "During doubly stochastic gradient descent, we are sampling from terms of\nthe analytic cost function, so it is not entirely instructive to plot\nthe cost versus optimization step---partial sums of the terms in the\nHamiltonian may have minimum energy below the ground state energy of the\ntotal Hamiltonian. Nevertheless, we can keep track of the cost value\nmoving average during doubly stochastic gradient descent as an indicator\nof convergence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def moving_average(data, n=3):\n    ret = np.cumsum(data, dtype=np.float64)\n    ret[n:] = ret[n:] - ret[:-n]\n    return ret[n - 1 :] / n\n\n\naverage = np.vstack([np.arange(25, 200), moving_average(cost, n=50)[:-26]])\n\nplt.plot(cost_GD, label=\"Vanilla gradient descent\")\nplt.plot(cost, \".\", label=\"Doubly QSGD\")\nplt.plot(average[0], average[1], \"--\", label=\"Doubly QSGD (moving average)\")\nplt.hlines(min_energy, 0, 200, linestyles=\":\", label=\"Ground state energy\")\n\nplt.ylabel(\"Cost function value\")\nplt.xlabel(\"Optimization steps\")\nplt.xlim(-2, 200)\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, verifying that the doubly stochastic gradient descent\noptimization correctly provides the ground state energy when evaluated\nfor a larger number of shots:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Doubly stochastic gradient descent min energy = \", qnode_analytic(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While stochastic gradient descent requires more optimization steps to\nachieve convergence, it is worth noting that it requires significantly\nfewer quantum device evaluations, and thus may as a result take less\ntime overall.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adaptive stochasticity\n======================\n\nTo improve on the convergence, we may even consider a crude \\\"adaptive\\\"\nmodification of the doubly stochastic gradient descent optimization\nperformed above. In this approach, we successively increase the number\nof terms we are sampling from as the optimization proceeds, as well as\nincreasing the number of shots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cost = []\nparams = init_params\nopt = qml.GradientDescentOptimizer(0.005)\n\nfor i in range(250):\n    n = min(i // 25 + 1, 5)\n    dev_stochastic.shots = int(1 + (n - 1) ** 2)\n\n    def loss(params):\n        return 4 + (5 / n) * circuit(params, n=n)\n\n    cost.append(loss(params))\n    params = opt.step(loss, params)\n\naverage = np.vstack([np.arange(25, 200), moving_average(cost, n=50)[:-26]])\n\nplt.plot(cost_GD, label=\"Vanilla gradient descent\")\nplt.plot(cost, \".\", label=\"Adaptive QSGD\")\nplt.plot(average[0], average[1], \"--\", label=\"Adaptive QSGD (moving average)\")\nplt.hlines(min_energy, 0, 250, linestyles=\":\", label=\"Ground state energy\")\n\nplt.ylabel(\"Cost function value\")\nplt.xlabel(\"Optimization steps\")\nplt.xlim(-2, 200)\nplt.legend()\nplt.show()\n\nprint(\"Adaptive QSGD min energy = \", qnode_analytic(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n==========\n\n1.  Ryan Sweke, Frederik Wilde, Johannes Jakob Meyer, Maria Schuld,\n    Paul K. F\u00e4hrmann, Barth\u00e9l\u00e9my Meynard-Piganeau, Jens Eisert.\n    \\\"Stochastic gradient descent for hybrid quantum-classical\n    optimization.\\\"\n    [arXiv:1910.01155](https://arxiv.org/abs/1910.01155), 2019.\n\nAbout the author\n================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}